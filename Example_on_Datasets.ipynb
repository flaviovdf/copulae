{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flaviovdf/copulae/blob/main/Example_on_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0eenMXFTSO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LlGHCmorIVx",
        "outputId": "0267dfc3-52fc-4c06-c562-f26230cf0b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-57ca1323\n"
          ]
        }
      ],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsQWN3Qutf1",
        "outputId": "49eb448d-d18d-4c33-bf32-3e2ff528f41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-udjfxkdi\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-udjfxkdi\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit 6537a8c6f08713a54ca87b6b981f592582354af6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.1)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.0)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.0.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.23)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.23.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.1.9)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.1)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from flake8->copulae==0.1) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from flake8->copulae==0.1) (2.11.1)\n",
            "Requirement already satisfied: pyflakes<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from flake8->copulae==0.1) (3.2.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax->copulae==0.1) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.17.0)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u3GILjJgBkOT"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from copulae.training import setup_training\n",
        "from copulae.training.loss import sq_error\n",
        "from copulae.training.loss import sq_error_partial\n",
        "from copulae.training.loss import copula_likelihood\n",
        "\n",
        "from copulae.training.cflax.mono_aux import EluPOne\n",
        "\n",
        "from copulae.training.cflax.two_cats import FlexibleBi\n",
        "from copulae.training.cflax.two_cats import NormalBi\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "from copulae.training.cflax.two_cats import TransformLayer\n",
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "\n",
        "from copulae.typing import Tensor\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "\n",
        "import copy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import pandas as pd\n",
        "import scipy.stats as ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sXqYmiT-uvNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8o-Btitw9v"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i59ZdlGCtyad"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KDHMLIEptyc3"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmnDKhjxtyfK",
        "outputId": "bce18452-b3d4-4143-dc8f-1b2ff0021571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gen-AC' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D8rTp88Ityhd"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8liWvEt7wZBm"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y2fnWDnywZEF"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wA7CUNiQ_VF7"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WoNLVJh9tyly"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrU2-FfguEXl"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7yCf4X_muQBI"
      },
      "outputs": [],
      "source": [
        "losses = [\n",
        "    (0.01, sq_error),\n",
        "    (0.5, sq_error_partial),\n",
        "    (0.1, copula_likelihood),\n",
        "]\n",
        "lr = 2e-3\n",
        "n_iter = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UmYBAhoVuExA"
      },
      "outputs": [],
      "source": [
        "losses_eval = [\n",
        "    (1.0, sq_error),\n",
        "    (1.0, sq_error_partial),\n",
        "    (1.0, copula_likelihood),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hxPVIuCsugBt"
      },
      "outputs": [],
      "source": [
        "layer_widths = [128, 64, 32, 16]\n",
        "model = TwoCats(           # 2 Cats\n",
        "    [                      # Is a sequence of\n",
        "        TransformLayer(    # Monotonic Transforms\n",
        "            PositiveLayer(layer_widths, EluPOne, EluPOne, EluPOne) # Defined by a positive NN\n",
        "        )\n",
        "    ],\n",
        "    FlexibleBi()           # Copulated with some bivariate CDF\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg99AIo7uKok"
      },
      "source": [
        "# Boston Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRJSg8VuLZc",
        "outputId": "f18e4efe-376e-4abb-cca2-5b3a51ff00bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 382)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_loader = Boston()\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "76b4JqYLueX4"
      },
      "outputs": [],
      "source": [
        "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
        "    model, TrainingTensors, losses, rescale=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bTPcrb9uu3L8"
      },
      "outputs": [],
      "source": [
        "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
        "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
        "del subkey\n",
        "\n",
        "params = init_params\n",
        "optimizer = optax.adam(lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3UHmBVUu5O-",
        "outputId": "dc28f4ea-2524-43da-d2bc-125888f5caae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:41<1:08:49, 41.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. Loss [[0.12098621 0.02244192 0.20316413]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [01:06<01:08,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. Loss [[ 0.11967535  0.01410873 -0.0207058 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 22/100 [01:07<00:10,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 20. Loss [[ 0.10689596  0.00976887 -0.1795828 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [01:08<00:08,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 30. Loss [[ 0.11163837  0.01610971 -0.1520264 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 42/100 [01:10<00:07,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 40. Loss [[ 0.11281525  0.00839911 -0.21861431]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 52/100 [01:11<00:07,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 50. Loss [[ 0.11198044  0.00566821 -0.24849118]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 62/100 [01:13<00:04,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 60. Loss [[ 0.11022259  0.00536646 -0.2920317 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 72/100 [01:14<00:04,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 70. Loss [[ 0.10879917  0.0064319  -0.28560784]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 82/100 [01:15<00:02,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. Loss [[ 0.10805281  0.0073262  -0.2341919 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 92/100 [01:17<00:01,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 90. Loss [[ 0.10772852  0.00922745 -0.27806988]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:18<00:00,  1.28it/s]\n"
          ]
        }
      ],
      "source": [
        "def L_d(losses, params, state):\n",
        "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
        "    for i, (w, loss_func) in enumerate(losses):\n",
        "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
        "    return loss\n",
        "\n",
        "best = 1e6\n",
        "for i in tqdm(range(n_iter)):\n",
        "    grads, cop_state = grad(params, cop_state)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    if i % 10 == 0:\n",
        "        loss = L_d(losses_eval, params, cop_state)\n",
        "        if loss[0][-1] < best:\n",
        "          best_params = params\n",
        "          best_cop_state = cop_state\n",
        "          best = loss[0][-1]\n",
        "        print('Iter {}. Loss {}'.format(i, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX-VRCYivJC2",
        "outputId": "4b430d9d-579d-4481-f258-2c331e8cf838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.06407911"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLPnSwayvDYV",
        "outputId": "233cef02-f77a-41e3-c222-4f8bcb23e41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.007874016 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-bf4ded0a2f4c>:7: RuntimeWarning: invalid value encountered in log\n",
            "  yhat = -np.log(points_density)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.13811676"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjKd8d6N2FpH",
        "outputId": "639204f8-3ad0-4e5f-f185-17ea4d2695e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.038025852,\n",
              " ConfidenceInterval(low=-0.20869317801744267, high=-0.05982864405031859))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "res = bootstrap(yhat, np.nanmean)\n",
        "res.standard_error, res.confidence_interval"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}