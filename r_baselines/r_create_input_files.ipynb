{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flaviovdf/copulae/blob/main/r_baselines/r_create_input_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe4ZqGRvGsNy"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ],
      "metadata": {
        "id": "9nGz3pcd8_SX",
        "outputId": "2ab0018b-3723-43fd-bb49-bc7609660bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-33961236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ],
      "metadata": {
        "id": "6tbWZyuA9EDJ",
        "outputId": "7807d52b-9b19-4009-c61e-aaa17a612d84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-g9273bui\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-g9273bui\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit 006a8cdf39eadae9803918962d9b6f3443327ecf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from copulae==0.1)\n",
            "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
            "Collecting flake8 (from copulae==0.1)\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
            "Building wheels for collected packages: copulae\n",
            "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=2b5b41ab52e20298c7df96a5eb3bd27d7aad4426434a605f729e5a25afc33aed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_iyfoyxw/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
            "Successfully built copulae\n",
            "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
            "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMWwyIqSGsN4"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import copy\n",
        "\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "import jax\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu1R6QheGsN7"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg6QkgM1GsN9"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QawRsraKGsN9"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = jss.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rR4NhfDGsN-"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL3U-FuxGsOA"
      },
      "source": [
        "## real data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MHNh1WzGsOB",
        "outputId": "2e5a5f12-8343-4440-a615-fae2c1cdabfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gen-AC'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
            "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
            "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (466/466), 10.28 MiB | 16.92 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMXBmCddGsOC"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYmULpN2GsOD"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHXfFxdjGsOE"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkfDV0L4GsOF"
      },
      "source": [
        "## synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6ZwBgMvGsOF"
      },
      "outputs": [],
      "source": [
        "def generate_gaussian(rho, sample_size=2000):\n",
        "    mean = np.zeros(2)\n",
        "    E = np.zeros(shape=(2, 2)) + rho\n",
        "    E[0, 0] = 1\n",
        "    E[1, 1] =1\n",
        "\n",
        "    D = np.random.multivariate_normal(mean=mean, cov=E, size=(sample_size, )).T\n",
        "\n",
        "    # Generating Train and test data\n",
        "    shuf_indexes = np.random.permutation(sample_size)\n",
        "\n",
        "    train_p = 0.75\n",
        "    n_train = int(D.shape[1] * train_p)\n",
        "    n_test = D.shape[1] - n_train\n",
        "\n",
        "    train_D = D[:, shuf_indexes[:n_train]]\n",
        "    test_D = D[:, shuf_indexes[n_train:]]\n",
        "\n",
        "    return train_D, test_D\n",
        "\n",
        "class Gauss():\n",
        "    def __init__(self, rho):\n",
        "        train_D, test_D = generate_gaussian(rho)\n",
        "\n",
        "        self.train_y = train_D[1, :].reshape(-1, 1)\n",
        "        self.train_x = train_D[0, :].reshape(-1, 1)\n",
        "        self.validation_y = test_D[1, :].reshape(-1, 1)\n",
        "        self.validation_x = test_D[0, :].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGo7MdbzGsOG"
      },
      "outputs": [],
      "source": [
        "# Marshal and Olkin\n",
        "def clayton_sample(theta):\n",
        "    alpha = 1 / theta\n",
        "    beta = 1\n",
        "    V = np.random.gamma(shape=alpha, scale=beta)\n",
        "    R = np.random.exponential(scale=1, size=2)\n",
        "    t = R / V\n",
        "    U = (1 + t) ** (-1/theta)\n",
        "    return U\n",
        "\n",
        "# Generate Clayton Copula with N(0,1) margins\n",
        "def generate_clayton_sample(theta, sample_size=2000):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for _ in range(sample_size):\n",
        "        U = clayton_sample(theta)\n",
        "        X.append(jss.norm.ppf(U[0]))\n",
        "        Y.append(jss.norm.ppf(U[1]))\n",
        "\n",
        "    D = np.concatenate((X, Y)).reshape((2, -1))\n",
        "\n",
        "    # Generating Train and test data\n",
        "    shuf_indexes = np.random.permutation(sample_size)\n",
        "\n",
        "    train_p = 0.75\n",
        "    n_train = int(D.shape[1] * train_p)\n",
        "    n_test = D.shape[1] - n_train\n",
        "\n",
        "    train_D = D[:, shuf_indexes[:n_train]]\n",
        "    test_D = D[:, shuf_indexes[n_train:]]\n",
        "\n",
        "    return train_D, test_D\n",
        "\n",
        "class Clayton():\n",
        "    def __init__(self, theta):\n",
        "        train_D, test_D = generate_clayton_sample(theta)\n",
        "        self.train_y = train_D[1, :].reshape(-1, 1)\n",
        "        self.train_x = train_D[0, :].reshape(-1, 1)\n",
        "        self.validation_y = test_D[1, :].reshape(-1, 1)\n",
        "        self.validation_x = test_D[0, :].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okAZsLYrGsOG"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import logser\n",
        "\n",
        "# Marshal and Olkin\n",
        "def frank_sample(theta):\n",
        "    p = 1 - np.exp(-theta)\n",
        "    V = logser.rvs(p)\n",
        "    R = np.random.exponential(scale=1, size=2)\n",
        "    t = R / V\n",
        "    U = -1/theta * np.log( 1 - ( (1 - np.exp(-theta)) * (np.exp(-t)) ) )\n",
        "    return U\n",
        "\n",
        "# Generate Frank Copula with N(0,1) margins\n",
        "def generate_frank_sample(theta, sample_size=2000):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for _ in range(sample_size):\n",
        "        U = frank_sample(theta)\n",
        "        X.append(jss.norm.ppf(U[0]))\n",
        "        Y.append(jss.norm.ppf(U[1]))\n",
        "\n",
        "    D = np.concatenate((X, Y)).reshape((2, -1))\n",
        "\n",
        "    # Generating Train and test data\n",
        "    shuf_indexes = np.random.permutation(sample_size)\n",
        "\n",
        "    train_p = 0.75\n",
        "    n_train = int(D.shape[1] * train_p)\n",
        "    n_test = D.shape[1] - n_train\n",
        "\n",
        "    train_D = D[:, shuf_indexes[:n_train]]\n",
        "    test_D = D[:, shuf_indexes[n_train:]]\n",
        "\n",
        "    return train_D, test_D\n",
        "\n",
        "class Frank():\n",
        "    def __init__(self, theta):\n",
        "        train_D, test_D = generate_frank_sample(theta)\n",
        "        self.train_y = train_D[1, :].reshape(-1, 1)\n",
        "        self.train_x = train_D[0, :].reshape(-1, 1)\n",
        "        self.validation_y = test_D[1, :].reshape(-1, 1)\n",
        "        self.validation_x = test_D[0, :].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ZLRiffGsOH"
      },
      "source": [
        "# get ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_mbg7Q2GsOI"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data\n",
        "! mkdir data/boston\n",
        "! mkdir data/intcmsft\n",
        "! mkdir data/googfb\n",
        "! mkdir data/gauss1\n",
        "! mkdir data/gauss5\n",
        "! mkdir data/gauss9\n",
        "! mkdir data/clayton1\n",
        "! mkdir data/clayton5\n",
        "! mkdir data/clayton10\n",
        "! mkdir data/frank1\n",
        "! mkdir data/frank5\n",
        "! mkdir data/frank10"
      ],
      "metadata": {
        "id": "oA5eGl0l-NkN",
        "outputId": "ca4a332f-d01d-4f73-db49-b56a93c223e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/boston’: File exists\n",
            "mkdir: cannot create directory ‘data/intcmsft’: File exists\n",
            "mkdir: cannot create directory ‘data/googfb’: File exists\n",
            "mkdir: cannot create directory ‘data/gauss1’: File exists\n",
            "mkdir: cannot create directory ‘data/gauss5’: File exists\n",
            "mkdir: cannot create directory ‘data/gauss9’: File exists\n",
            "mkdir: cannot create directory ‘data/clayton1’: File exists\n",
            "mkdir: cannot create directory ‘data/clayton5’: File exists\n",
            "mkdir: cannot create directory ‘data/clayton10’: File exists\n",
            "mkdir: cannot create directory ‘data/frank1’: File exists\n",
            "mkdir: cannot create directory ‘data/frank5’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j1FhBgIGsOJ"
      },
      "outputs": [],
      "source": [
        "data_loader = Boston()\n",
        "ds = 'boston'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = INTC_MSFT()\n",
        "ds = 'intcmsft'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = GOOG_FB()\n",
        "ds = 'googfb'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Gauss(rho = 0.1)\n",
        "ds = 'gauss1'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Gauss(rho = 0.5)\n",
        "ds = 'gauss5'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Gauss(rho = 0.9)\n",
        "ds = 'gauss9'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "\n",
        "data_loader = Clayton(theta = 1)\n",
        "ds = 'clayton1'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Clayton(theta = 5)\n",
        "ds = 'clayton5'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Clayton(theta = 10)\n",
        "ds = 'clayton10'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Frank(theta = 1)\n",
        "ds = 'frank1'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Frank(theta = 5)\n",
        "ds = 'frank5'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')\n",
        "\n",
        "\n",
        "data_loader = Frank(theta = 10)\n",
        "ds = 'frank10'\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "_, _, cdf_xy_trn = get_set(D, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/trn.csv'.format(ds), cdf_xy_trn[0, :, :].T, delimiter = ',')\n",
        "_, _, cdf_xy_tst = get_set(D_val, TrainingTensors.X_batches[0])\n",
        "np.savetxt('data/{}/tst.csv'.format(ds), cdf_xy_tst[0, :, :].T, delimiter = ',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r data.zip data/"
      ],
      "metadata": {
        "id": "KEGJgnMhC5SC",
        "outputId": "1e0c7a9b-33cf-4222-d750-b46bc9800bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data/ (stored 0%)\n",
            "  adding: data/boston/ (stored 0%)\n",
            "  adding: data/boston/tst.csv (deflated 53%)\n",
            "  adding: data/boston/trn.csv (deflated 55%)\n",
            "  adding: data/frank10/ (stored 0%)\n",
            "  adding: data/frank10/tst.csv (deflated 55%)\n",
            "  adding: data/frank10/trn.csv (deflated 57%)\n",
            "  adding: data/intcmsft/ (stored 0%)\n",
            "  adding: data/intcmsft/tst.csv (deflated 55%)\n",
            "  adding: data/intcmsft/trn.csv (deflated 56%)\n",
            "  adding: data/gauss9/ (stored 0%)\n",
            "  adding: data/gauss9/tst.csv (deflated 55%)\n",
            "  adding: data/gauss9/trn.csv (deflated 57%)\n",
            "  adding: data/frank1/ (stored 0%)\n",
            "  adding: data/frank1/tst.csv (deflated 55%)\n",
            "  adding: data/frank1/trn.csv (deflated 57%)\n",
            "  adding: data/gauss5/ (stored 0%)\n",
            "  adding: data/gauss5/tst.csv (deflated 55%)\n",
            "  adding: data/gauss5/trn.csv (deflated 57%)\n",
            "  adding: data/frank5/ (stored 0%)\n",
            "  adding: data/frank5/tst.csv (deflated 55%)\n",
            "  adding: data/frank5/trn.csv (deflated 57%)\n",
            "  adding: data/gauss1/ (stored 0%)\n",
            "  adding: data/gauss1/tst.csv (deflated 55%)\n",
            "  adding: data/gauss1/trn.csv (deflated 57%)\n",
            "  adding: data/clayton10/ (stored 0%)\n",
            "  adding: data/clayton10/tst.csv (deflated 55%)\n",
            "  adding: data/clayton10/trn.csv (deflated 57%)\n",
            "  adding: data/clayton5/ (stored 0%)\n",
            "  adding: data/clayton5/tst.csv (deflated 55%)\n",
            "  adding: data/clayton5/trn.csv (deflated 57%)\n",
            "  adding: data/googfb/ (stored 0%)\n",
            "  adding: data/googfb/tst.csv (deflated 54%)\n",
            "  adding: data/googfb/trn.csv (deflated 56%)\n",
            "  adding: data/clayton1/ (stored 0%)\n",
            "  adding: data/clayton1/tst.csv (deflated 55%)\n",
            "  adding: data/clayton1/trn.csv (deflated 57%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs5xHh2rGsOO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "copulae",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}