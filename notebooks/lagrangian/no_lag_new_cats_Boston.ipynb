{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy0eenMXFTSO"
   },
   "source": [
    "# Setup\n",
    "\n",
    "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LlGHCmorIVx",
    "outputId": "e9e114b5-4fe7-4ce7-a171-58cdf8d4fe82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# github.com:22 SSH-2.0-babeld-33961236\n"
     ]
    }
   ],
   "source": [
    "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
    "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
    "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
    "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
    "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
    "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
    "-----END OPENSSH PRIVATE KEY-----\n",
    "\"\"\"\n",
    "\n",
    "# Create the directory if it doesn't exist.\n",
    "! mkdir -p /root/.ssh\n",
    "# Write the key\n",
    "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
    "    f.write(GITHUB_PRIVATE_KEY)\n",
    "# Add github.com to our known hosts\n",
    "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
    "# Restrict the key permissions, or else SSH will complain.\n",
    "! chmod go-rwx /root/.ssh/id_ed25519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqsQWN3Qutf1",
    "outputId": "4d5e197a-1c74-4351-dad6-be2e369094a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
      "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-2119plgu\n",
      "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-2119plgu\n",
      "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit c3850f012d0e128956573f7db0bacd8a12b84827\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting coverage (from copulae==0.1)\n",
      "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
      "Collecting flake8 (from copulae==0.1)\n",
      "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
      "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
      "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
      "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
      "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
      "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
      "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
      "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
      "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
      "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
      "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
      "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
      "Building wheels for collected packages: copulae\n",
      "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=a536639ddba843c6c18103595ce8d37ccac2fbc9c93dcdb36a73c3aea64bcd25\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z02xyoe1/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
      "Successfully built copulae\n",
      "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
      "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
     ]
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "! pip install {userdata.get('twocatsrepo')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3GILjJgBkOT"
   },
   "outputs": [],
   "source": [
    "from copulae.input import generate_copula_net_input\n",
    "\n",
    "from copulae.training import setup_training\n",
    "from copulae.training.loss import sq_error\n",
    "from copulae.training.loss import sq_error_partial\n",
    "from copulae.training.loss import copula_likelihood\n",
    "\n",
    "from copulae.training.cflax.mono_aux import EluPOne\n",
    "\n",
    "from copulae.training.cflax.two_cats import FlexibleBi\n",
    "from copulae.training.cflax.two_cats import NormalBi\n",
    "from copulae.training.cflax.two_cats import PositiveLayer\n",
    "from copulae.training.cflax.two_cats import TransformLayer\n",
    "from copulae.training.cflax.two_cats import TwoCats\n",
    "\n",
    "from copulae.typing import Tensor\n",
    "\n",
    "from scipy.stats import bootstrap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "import copy\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.stats as jss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "import pandas as pd\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXqYmiT-uvNP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH8o-Btitw9v"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i59ZdlGCtyad"
   },
   "outputs": [],
   "source": [
    "def add_train_random_noise(data, num_adds):\n",
    "    new_data = np.random.rand(num_adds, data.shape[1])\n",
    "    return np.concatenate((data, new_data), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDHMLIEptyc3"
   },
   "outputs": [],
   "source": [
    "def rank_normalization(X):\n",
    "    X = copy.deepcopy(X)\n",
    "    for z in X:\n",
    "        ndata = z.shape[0]\n",
    "        gap = 1./(ndata+1)\n",
    "        nfeats = z.shape[1]\n",
    "        for i in range(nfeats):\n",
    "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmnDKhjxtyfK",
    "outputId": "ef31f84f-c227-4839-b22e-e5af4f2dc457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gen-AC'...\n",
      "remote: Enumerating objects: 466, done.\u001b[K\n",
      "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
      "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
      "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (466/466), 10.28 MiB | 34.62 MiB/s, done.\n",
      "Resolving deltas: 100% (159/159), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/yutingng/gen-AC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8rTp88Ityhd"
   },
   "outputs": [],
   "source": [
    "class Boston():\n",
    "    def __init__(self):\n",
    "        # read\n",
    "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
    "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "        y = raw_df.values[1::2, 2]\n",
    "\n",
    "        # split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
    "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
    "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
    "\n",
    "        # norm\n",
    "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
    "\n",
    "        # noise\n",
    "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
    "\n",
    "        # 2d\n",
    "        train_data = X_train[:, [0, 13]]\n",
    "        test_data = X_test[:, [0, 13]]\n",
    "\n",
    "        # flip\n",
    "        train_data[:, 0] = 1 - train_data[:, 0]\n",
    "        test_data[:, 0] = 1 - test_data[:, 0]\n",
    "\n",
    "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
    "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
    "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
    "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8liWvEt7wZBm"
   },
   "outputs": [],
   "source": [
    "class INTC_MSFT():\n",
    "    def __init__(self):\n",
    "        # read\n",
    "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
    "        intel = np.array(list(map(float, intel_f.readlines())))\n",
    "\n",
    "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
    "        ms = np.array(list(map(float, ms_f.readlines())))\n",
    "\n",
    "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
    "        ge = np.array(list(map(float, ge_f.readlines())))\n",
    "\n",
    "        # split\n",
    "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
    "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
    "\n",
    "        # norm\n",
    "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
    "\n",
    "        # 2d, noise\n",
    "        train_data = X_train[:, [0, 1]]\n",
    "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
    "        test_data = X_test[:, [0, 1]]\n",
    "\n",
    "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
    "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
    "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
    "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2fnWDnywZEF"
   },
   "outputs": [],
   "source": [
    "class GOOG_FB():\n",
    "    def __init__(self):\n",
    "        # read\n",
    "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
    "        goog = np.array(list(map(float, goog_f.readlines())))\n",
    "\n",
    "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
    "        fb = np.array(list(map(float, fb_f.readlines())))\n",
    "\n",
    "        # split\n",
    "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
    "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
    "\n",
    "        # norm\n",
    "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
    "\n",
    "        # 2d, noise\n",
    "        train_data = X_train[:, [0, 1]]\n",
    "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
    "        test_data = X_test[:, [0, 1]]\n",
    "\n",
    "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
    "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
    "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
    "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA7CUNiQ_VF7"
   },
   "outputs": [],
   "source": [
    "def get_set(D_val, data_points):\n",
    "    points = D_val\n",
    "    points = jnp.expand_dims(points, axis=0)\n",
    "\n",
    "    # PDF and CDF for X\n",
    "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
    "    density_x = kde_x.evaluate(points[0, 0, :])\n",
    "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
    "\n",
    "    # PDF and CDF for Y\n",
    "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
    "    density_y = kde_y.evaluate(points[0, 1, :])\n",
    "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
    "\n",
    "    I_pdf = density_x.T * density_y.T\n",
    "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
    "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
    "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
    "\n",
    "    del density_x\n",
    "    del density_y\n",
    "    del cumulative_x\n",
    "    del cumulative_y\n",
    "\n",
    "    return points, I_pdf, cdf_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoNLVJh9tyly"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30091985)\n",
    "key = jax.random.PRNGKey(30091985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrU2-FfguEXl"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yCf4X_muQBI"
   },
   "outputs": [],
   "source": [
    "losses = [\n",
    "    (0.01, sq_error),\n",
    "    (0.5, sq_error_partial),\n",
    "    (0.1, copula_likelihood),\n",
    "]\n",
    "lr = 2e-3\n",
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmYBAhoVuExA"
   },
   "outputs": [],
   "source": [
    "losses_eval = [\n",
    "    (1.0, sq_error),\n",
    "    (1.0, sq_error_partial),\n",
    "    (1.0, copula_likelihood),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxPVIuCsugBt"
   },
   "outputs": [],
   "source": [
    "layer_widths = [128, 64, 32, 16]\n",
    "model = TwoCats(           # 2 Cats\n",
    "    [                      # Is a sequence of\n",
    "        TransformLayer(    # Monotonic Transforms\n",
    "            PositiveLayer(\n",
    "                #nn.Dense,\n",
    "                layer_widths,\n",
    "                EluPOne, EluPOne, EluPOne\n",
    "            ) # Defined by a positive NN\n",
    "        )\n",
    "    ],\n",
    "    FlexibleBi()           # Copulated with some bivariate CDF\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hg99AIo7uKok"
   },
   "source": [
    "# Boston Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlRJSg8VuLZc",
    "outputId": "86f55cf1-66ed-4bae-ba4a-5c246413ec05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 382)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = Boston()\n",
    "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
    "TrainingTensors = generate_copula_net_input(\n",
    "    D=D,\n",
    "    bootstrap=False\n",
    ")\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUtS9DAHIriV"
   },
   "outputs": [],
   "source": [
    "def lagrangian(params, cop_state, nn_C, nn_dC):\n",
    "    Ex_M0 = cop_state.UV_batches[:, 0, :].ravel()\n",
    "    In_M0 = cop_state.UV_batches.at[:, 1, :].set(1)\n",
    "\n",
    "    Ex_M1 = cop_state.UV_batches[:, 1, :].ravel()\n",
    "    In_M1 = cop_state.UV_batches.at[:, 0, :].set(1)\n",
    "\n",
    "    Pr_M0_H = nn_C(params, In_M0).ravel()\n",
    "    Pr_M1_H = nn_C(params, In_M1).ravel()\n",
    "\n",
    "    Pr_M0_dH = nn_dC(params, In_M0)[:, 1, :].ravel()\n",
    "    Pr_M1_dH = nn_dC(params, In_M1)[:, 0, :].ravel()\n",
    "\n",
    "    lag_0 = (Pr_M0_H - Ex_M0) * (Pr_M0_dH - 1)\n",
    "    lag_1 = (Pr_M1_H - Ex_M1) * (Pr_M1_dH - 1)\n",
    "\n",
    "    return (lag_0 + lag_1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76b4JqYLueX4"
   },
   "outputs": [],
   "source": [
    "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
    "    model, TrainingTensors, losses, rescale=True\n",
    ")\n",
    "\n",
    "def new_forward(params, cop_state, penalty):\n",
    "    f =  forward(params, cop_state)\n",
    "    l =  f[0]\n",
    "    # l += lagrangian(params, cop_state, nn_C, nn_dC)\n",
    "    return l, f[1]\n",
    "\n",
    "new_grad = jax.grad(new_forward, has_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTPcrb9uu3L8"
   },
   "outputs": [],
   "source": [
    "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
    "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
    "del subkey\n",
    "\n",
    "params = init_params\n",
    "optimizer = optax.adam(lr)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3UHmBVUu5O-",
    "outputId": "4048919a-d412-4c24-bf90-74886249d33d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:35<9:54:57, 35.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0. Loss [[0.12098621 0.02244192 0.20316386]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:54<10:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10. Loss [[ 0.12010325  0.01503656 -0.01221563]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [00:56<02:15,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss [[ 0.10639331  0.01134215 -0.1006257 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [00:57<01:42,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30. Loss [[ 0.10601941  0.01191132 -0.17511234]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1000 [00:58<01:54,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss [[ 0.10681837  0.01071424 -0.21126439]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:59<01:42,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50. Loss [[0.11752599 0.01810858 0.00685073]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1000 [01:00<01:48,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss [[ 0.11760194  0.01054229 -0.15135592]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [01:02<01:41,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 70. Loss [[ 0.11308529  0.00913379 -0.21231477]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 82/1000 [01:03<01:46,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss [[ 0.11145155  0.0063389  -0.2179331 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 92/1000 [01:04<01:36,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90. Loss [[ 0.11345994  0.00776681 -0.29768217]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [01:05<01:41,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100. Loss [[ 0.11052932  0.00636703 -0.2857596 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 112/1000 [01:06<01:32,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 110. Loss [[ 0.10930618  0.00623173 -0.3078484 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 122/1000 [01:08<01:39,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120. Loss [[ 0.10915145  0.0097328  -0.2861345 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 131/1000 [01:09<01:31,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130. Loss [[ 0.11064944  0.00615632 -0.33927983]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 142/1000 [01:10<01:33,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140. Loss [[ 0.1092306   0.00802163 -0.3411147 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [01:11<01:57,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150. Loss [[ 0.10920897  0.0060876  -0.34922427]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 162/1000 [01:12<01:34,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160. Loss [[ 0.10923356  0.00640074 -0.36197227]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 172/1000 [01:14<01:59,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 170. Loss [[ 0.10971196  0.00710019 -0.37818885]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 182/1000 [01:15<01:30,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180. Loss [[ 0.10944404  0.00677763 -0.3865782 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 192/1000 [01:16<01:45,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190. Loss [[ 0.10907026  0.00753612 -0.40084544]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [01:17<01:29,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200. Loss [[ 0.10963907  0.00824862 -0.4065468 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 212/1000 [01:19<01:37,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 210. Loss [[ 0.11139579  0.00782924 -0.20268394]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 222/1000 [01:20<01:24,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220. Loss [[ 0.10978714  0.01079584 -0.21176563]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 232/1000 [01:21<01:31,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 230. Loss [[ 0.10879739  0.01091474 -0.2518208 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [01:22<01:23,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240. Loss [[ 0.10761518  0.0110816  -0.25905076]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [01:23<01:24,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 250. Loss [[0.11858045 0.01550819 0.0120343 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 262/1000 [01:24<01:21,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260. Loss [[ 0.11714125  0.01306692 -0.00917969]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 272/1000 [01:26<01:24,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 270. Loss [[ 0.11629701  0.01099035 -0.04625686]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 282/1000 [01:27<01:14,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280. Loss [[ 0.11540945  0.0095041  -0.07742947]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 292/1000 [01:28<01:22,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 290. Loss [[ 0.11428199  0.00848742 -0.11654555]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [01:29<01:17,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300. Loss [[ 0.11275829  0.0084748  -0.1684645 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 312/1000 [01:30<01:17,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310. Loss [[ 0.11098454  0.00649338 -0.22010122]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [01:31<01:10,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320. Loss [[ 0.10795533  0.00493686 -0.27959555]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 332/1000 [01:33<01:10,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 330. Loss [[ 0.10791701  0.00510003 -0.29931664]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 342/1000 [01:34<01:39,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340. Loss [[ 0.10814372  0.00450459 -0.31320786]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [01:35<01:08,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 350. Loss [[ 0.10906808  0.00432865 -0.3220284 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 362/1000 [01:36<01:29,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360. Loss [[ 0.10942118  0.00404515 -0.32963753]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 372/1000 [01:37<01:04,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 370. Loss [[ 0.10946909  0.00413537 -0.34097144]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 382/1000 [01:39<01:15,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380. Loss [[ 0.10976214  0.00403956 -0.35096473]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 392/1000 [01:40<01:02,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 390. Loss [[ 0.10978769  0.00399217 -0.35700932]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [01:41<01:09,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400. Loss [[ 0.11365981  0.00454916 -0.29646617]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 412/1000 [01:42<01:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410. Loss [[ 0.11518451  0.00676364 -0.22989675]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 422/1000 [01:43<01:07,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420. Loss [[ 0.11218634  0.00517826 -0.2800624 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 432/1000 [01:44<00:58,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 430. Loss [[ 0.10992687  0.00486929 -0.34114954]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 443/1000 [01:46<00:59,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440. Loss [[ 0.10919461  0.0041595  -0.35255352]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [01:46<00:56,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 450. Loss [[ 0.10988948  0.00392807 -0.3636566 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 462/1000 [01:48<00:59,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460. Loss [[ 0.11020614  0.0038594  -0.3688021 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 472/1000 [01:49<00:56,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 470. Loss [[ 0.11016998  0.0041104  -0.37439284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 482/1000 [01:50<00:55,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 480. Loss [[ 0.1104295   0.00412657 -0.3784859 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [01:51<00:51,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 490. Loss [[ 0.11045384  0.00414132 -0.38204828]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:52<00:51,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500. Loss [[ 0.11059662  0.00428417 -0.38588318]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 511/1000 [01:53<00:51,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 510. Loss [[ 0.11067781  0.00439027 -0.389849  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 523/1000 [01:55<00:49,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 520. Loss [[ 0.11067219  0.00455475 -0.3944809 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 532/1000 [01:56<01:05,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 530. Loss [[ 0.11077437  0.00483863 -0.39995715]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 543/1000 [01:57<00:46,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 540. Loss [[ 0.11072654  0.00499571 -0.4049036 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 552/1000 [01:58<00:55,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 550. Loss [[ 0.11059863  0.00528764 -0.41239297]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 562/1000 [01:59<00:47,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 560. Loss [[ 0.1165702   0.01015123 -0.2321076 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 572/1000 [02:00<00:56,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 570. Loss [[ 0.11585644  0.0083665  -0.21516088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 582/1000 [02:02<00:45,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 580. Loss [[ 0.11177399  0.00444019 -0.284737  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 592/1000 [02:03<00:49,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 590. Loss [[ 0.10972731  0.00423101 -0.33932695]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 602/1000 [02:04<00:40,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 600. Loss [[ 0.10942684  0.00415901 -0.35832414]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 612/1000 [02:05<00:44,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610. Loss [[ 0.10922995  0.00447878 -0.3781012 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 622/1000 [02:06<00:40,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 620. Loss [[ 0.10947619  0.00496627 -0.38920906]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 633/1000 [02:07<00:38,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 630. Loss [[ 0.10986881  0.004818   -0.39351007]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 642/1000 [02:08<00:35,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 640. Loss [[ 0.11034692  0.0045856  -0.396356  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [02:10<00:38,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 650. Loss [[ 0.11074533  0.00448356 -0.39900595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 662/1000 [02:11<00:35,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 660. Loss [[ 0.11107323  0.00451971 -0.40177926]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 672/1000 [02:12<00:35,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 670. Loss [[ 0.11091232  0.00484672 -0.40566272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 682/1000 [02:13<00:32,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 680. Loss [[ 0.11094999  0.00482789 -0.4083637 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 692/1000 [02:14<00:32,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 690. Loss [[ 0.1107241   0.00495262 -0.41252688]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [02:15<00:30,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700. Loss [[ 0.11058872  0.00516576 -0.41702056]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 712/1000 [02:16<00:30,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 710. Loss [[ 0.11016529  0.0055719  -0.4239141 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 722/1000 [02:18<00:39,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 720. Loss [[ 0.11015361  0.00603424 -0.43266988]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 732/1000 [02:19<00:28,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 730. Loss [[ 0.11973871  0.01112291 -0.20239526]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 742/1000 [02:20<00:33,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 740. Loss [[ 0.11797466  0.00901774 -0.18425076]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [02:21<00:25,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750. Loss [[ 0.11614557  0.006156   -0.21289913]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 762/1000 [02:22<00:31,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 760. Loss [[ 0.11501498  0.00522023 -0.22809501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 772/1000 [02:23<00:24,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770. Loss [[ 0.11421421  0.00460764 -0.24506849]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 782/1000 [02:24<00:25,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 780. Loss [[ 0.11375195  0.00425109 -0.26453638]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 792/1000 [02:26<00:21,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 790. Loss [[ 0.11322177  0.0039497  -0.2839306 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [02:27<00:22,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 800. Loss [[ 0.1127164   0.00395589 -0.30235946]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 812/1000 [02:28<00:19,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 810. Loss [[ 0.1121144   0.00418583 -0.31653723]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 822/1000 [02:29<00:19,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 820. Loss [[ 0.11161897  0.00414173 -0.32619414]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 832/1000 [02:30<00:16,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 830. Loss [[ 0.11120345  0.00412546 -0.3326348 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 842/1000 [02:31<00:17,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 840. Loss [[ 0.11082527  0.00414473 -0.33909017]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [02:32<00:15,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 850. Loss [[ 0.11053211  0.004049   -0.34462312]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 862/1000 [02:34<00:15,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 860. Loss [[ 0.11030334  0.00395349 -0.3503054 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 872/1000 [02:35<00:13,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 870. Loss [[ 0.11008679  0.00395301 -0.35639292]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [02:36<00:12,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 880. Loss [[ 0.1098086   0.00403013 -0.36066377]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 890/1000 [02:37<00:11,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 890. Loss [[ 0.10998945  0.00403001 -0.36496684]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [02:38<00:10,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 900. Loss [[ 0.11023208  0.00402152 -0.36901036]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 911/1000 [02:39<00:09,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 910. Loss [[ 0.1103054   0.00405785 -0.372723  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 922/1000 [02:40<00:08,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 920. Loss [[ 0.11033836  0.00411176 -0.37755564]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 932/1000 [02:42<00:10,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 930. Loss [[ 0.11027034  0.00421578 -0.38442674]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 942/1000 [02:43<00:06,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 940. Loss [[ 0.10990071  0.00450702 -0.3933775 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [02:44<00:06,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 950. Loss [[ 0.10982624  0.0047658  -0.40144578]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 962/1000 [02:45<00:04,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 960. Loss [[ 0.10981931  0.00511257 -0.4090843 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 972/1000 [02:46<00:03,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 970. Loss [[ 0.10990353  0.00533021 -0.41543746]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 982/1000 [02:47<00:01,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 980. Loss [[ 0.11000761  0.00549386 -0.4207544 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 992/1000 [02:49<00:00,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 990. Loss [[ 0.11012962  0.00568317 -0.42611104]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:49<00:00,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "def L_d(losses, params, state):\n",
    "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
    "    for i, (w, loss_func) in enumerate(losses):\n",
    "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
    "    return loss\n",
    "\n",
    "best = 1e6\n",
    "mu = 1\n",
    "alpha = 0.95\n",
    "# penalty = 1.0\n",
    "for i in tqdm(range(n_iter)):\n",
    "    grads, cop_state = new_grad(params, cop_state, mu)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    mu = mu * alpha\n",
    "    # penalty += 0.01 * penalty\n",
    "    loss = L_d(losses_eval, params, cop_state)\n",
    "    if not jnp.isnan(loss).any():\n",
    "        best_params = params\n",
    "        best_cop_state = cop_state\n",
    "        best = loss[0][-1]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print('Iter {}. Loss {}'.format(i, loss))\n",
    "\n",
    "# best_params = params\n",
    "# best_cop_state = cop_state\n",
    "# best = loss[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "KfHQloco9FlR",
    "outputId": "70577056-5063-471a-bd8e-f69377b1ac13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.48167538, 0.59685863, 0.68062826, 0.75130889, 0.81675392,\n",
       "        0.87434554, 0.92408376, 0.96596858, 0.98952879, 0.99999999]),\n",
       " array([-0.00486738,  0.01828739,  0.04144215,  0.06459691,  0.08775168,\n",
       "         0.11090644,  0.1340612 ,  0.15721597,  0.18037073,  0.2035255 ,\n",
       "         0.22668026]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ex_M0 = TrainingTensors.UV_batches[:, 0, :].ravel()\n",
    "In_M0 = TrainingTensors.UV_batches.at[:, 1, :].set(1)\n",
    "\n",
    "Ex_M1 = TrainingTensors.UV_batches[:, 1, :].ravel()\n",
    "In_M1 = TrainingTensors.UV_batches.at[:, 0, :].set(1)\n",
    "\n",
    "Pr_M0 = nn_C(params, In_M0).ravel()\n",
    "Pr_M1 = nn_C(params, In_M1).ravel()\n",
    "\n",
    "plt.hist((Ex_M0 - Pr_M0) / Ex_M0, cumulative=True, density=True, edgecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "ci44OZkz9_vq",
    "outputId": "f6b66167-b910-4cab-8982-13098a7909ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.42931935, 0.57329841, 0.69109946, 0.7931937 , 0.88481673,\n",
       "        0.94764396, 0.97643977, 0.98952878, 0.99476438, 0.99999998]),\n",
       " array([-0.01287222,  0.02726264,  0.0673975 ,  0.10753236,  0.14766721,\n",
       "         0.18780208,  0.22793694,  0.2680718 ,  0.30820665,  0.34834152,\n",
       "         0.38847637]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist((Ex_M1 - Pr_M1) / Ex_M1, cumulative=True, density=True, edgecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KX-VRCYivJC2",
    "outputId": "3aab6d66-7201-4d60-8f95-7067824da06f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.1326973"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
    "\n",
    "copula_density = nn_c(best_params, cdf_xy)\n",
    "points_density = copula_density * I_pdf\n",
    "print((points_density < 0).mean(), (points_density < 0).sum())\n",
    "yhat = -np.log(points_density)\n",
    "np.nanmean(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLPnSwayvDYV",
    "outputId": "e9ce0e6b-4ce9-4bd5-c35b-d0ba4513a1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007874016 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-bf4ded0a2f4c>:7: RuntimeWarning: invalid value encountered in log\n",
      "  yhat = -np.log(points_density)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.17461577"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
    "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
    "\n",
    "copula_density = nn_c(best_params, cdf_xy)\n",
    "points_density = copula_density * I_pdf\n",
    "print((points_density < 0).mean(), (points_density < 0).sum())\n",
    "yhat = -np.log(points_density)\n",
    "np.nanmean(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjKd8d6N2FpH",
    "outputId": "33ddcc5c-679a-4ccd-9b47-1c86fe5140eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.040365387,\n",
       " ConfidenceInterval(low=-0.2459724425554656, high=-0.08605947122113178))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = bootstrap(yhat, np.nanmean)\n",
    "res.standard_error, res.confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf5LV4s0L_sZ",
    "outputId": "6c1f6bd5-45cb-4afd-c1a5-1bda7b5e9cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(7.6876564, dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (jnp.abs(Ex_M1 - Pr_M1) / Ex_M1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6QkhTQFAUOj",
    "outputId": "48d87a8e-321a-46bb-dce7-bbabf3da8f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4.997569, dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (jnp.abs(Ex_M0 - Pr_M0) / Ex_M0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeGG3VLXxNgi",
    "outputId": "58d533d2-3457-4365-8dee-0438ce06f81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.00998721, dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(jnp.abs(Ex_M0 - Pr_M0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uh0doHfMAV_F",
    "outputId": "3794cccc-d6e7-4b2a-d2c8-cc9c08db7dab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.01753025, dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(jnp.abs(Ex_M1 - Pr_M1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj3KMf0J0shG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
