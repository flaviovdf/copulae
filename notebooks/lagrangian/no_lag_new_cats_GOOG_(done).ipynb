{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0eenMXFTSO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LlGHCmorIVx",
        "outputId": "520ff02e-cd1f-461a-dbf9-92bf6bd1cb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-33961236\n"
          ]
        }
      ],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsQWN3Qutf1",
        "outputId": "0202cd67-c98c-4d2c-df13-fe40abbb3703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-vlmo2lwb\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-vlmo2lwb\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit c3850f012d0e128956573f7db0bacd8a12b84827\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from copulae==0.1)\n",
            "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
            "Collecting flake8 (from copulae==0.1)\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
            "Building wheels for collected packages: copulae\n",
            "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=da16b27d07f2aff17a3fdc68cbefa59d1176b2a5f665791e89da9e144deb0e94\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b3nb6ngb/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
            "Successfully built copulae\n",
            "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
            "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3GILjJgBkOT"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from copulae.training import setup_training\n",
        "from copulae.training.loss import sq_error\n",
        "from copulae.training.loss import sq_error_partial\n",
        "from copulae.training.loss import copula_likelihood\n",
        "\n",
        "from copulae.training.cflax.mono_aux import EluPOne\n",
        "\n",
        "from copulae.training.cflax.two_cats import FlexibleBi\n",
        "from copulae.training.cflax.two_cats import NormalBi\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "from copulae.training.cflax.two_cats import TransformLayer\n",
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "\n",
        "from copulae.typing import Tensor\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "\n",
        "import copy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import pandas as pd\n",
        "import scipy.stats as ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqYmiT-uvNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8o-Btitw9v"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59ZdlGCtyad"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDHMLIEptyc3"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmnDKhjxtyfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d7185f-3a09-4175-ecc2-073c32f3d67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gen-AC'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
            "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
            "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (466/466), 10.28 MiB | 8.98 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8rTp88Ityhd"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8liWvEt7wZBm"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2fnWDnywZEF"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA7CUNiQ_VF7"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoNLVJh9tyly"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrU2-FfguEXl"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yCf4X_muQBI"
      },
      "outputs": [],
      "source": [
        "losses = [\n",
        "    (0.01, sq_error),\n",
        "    (0.5, sq_error_partial),\n",
        "    (0.1, copula_likelihood),\n",
        "]\n",
        "lr = 2e-3\n",
        "n_iter = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmYBAhoVuExA"
      },
      "outputs": [],
      "source": [
        "losses_eval = [\n",
        "    (1.0, sq_error),\n",
        "    (1.0, sq_error_partial),\n",
        "    (1.0, copula_likelihood),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxPVIuCsugBt"
      },
      "outputs": [],
      "source": [
        "layer_widths = [128, 64, 32, 16]\n",
        "model = TwoCats(           # 2 Cats\n",
        "    [                      # Is a sequence of\n",
        "        TransformLayer(    # Monotonic Transforms\n",
        "            PositiveLayer(\n",
        "                layer_widths,\n",
        "                EluPOne, EluPOne, EluPOne\n",
        "            ) # Defined by a positive NN\n",
        "        )\n",
        "    ],\n",
        "    FlexibleBi()           # Copulated with some bivariate CDF\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg99AIo7uKok"
      },
      "source": [
        "# Boston Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlRJSg8VuLZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a53e64-c599-424e-c3dc-53ba30dbc406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 953)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_loader = GOOG_FB()\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lagrangian(params, cop_state, nn_C, nn_dC):\n",
        "    Ex_M0 = cop_state.UV_batches[:, 0, :].ravel()\n",
        "    In_M0 = cop_state.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "    Ex_M1 = cop_state.UV_batches[:, 1, :].ravel()\n",
        "    In_M1 = cop_state.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "    Pr_M0_H = nn_C(params, In_M0).ravel()\n",
        "    Pr_M1_H = nn_C(params, In_M1).ravel()\n",
        "\n",
        "    Pr_M0_dH = nn_dC(params, In_M0)[:, 1, :].ravel()\n",
        "    Pr_M1_dH = nn_dC(params, In_M1)[:, 0, :].ravel()\n",
        "\n",
        "    lag_0 = (Pr_M0_H - Ex_M0) * (Pr_M0_dH - 1)\n",
        "    lag_1 = (Pr_M1_H - Ex_M1) * (Pr_M1_dH - 1)\n",
        "\n",
        "    return (lag_0 + lag_1).mean()"
      ],
      "metadata": {
        "id": "JUtS9DAHIriV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b4JqYLueX4"
      },
      "outputs": [],
      "source": [
        "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
        "    model, TrainingTensors, losses, rescale=True\n",
        ")\n",
        "\n",
        "def new_forward(params, cop_state, penalty):\n",
        "    f =  forward(params, cop_state)\n",
        "    l =  f[0]\n",
        "    # l += lagrangian(params, cop_state, nn_C, nn_dC)\n",
        "    return l, f[1]\n",
        "\n",
        "new_grad = jax.grad(new_forward, has_aux=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTPcrb9uu3L8"
      },
      "outputs": [],
      "source": [
        "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
        "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
        "del subkey\n",
        "\n",
        "params = init_params\n",
        "optimizer = optax.adam(lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3UHmBVUu5O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa574d1-badd-47c4-d861-9483e2da73ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1000 [00:36<10:08:31, 36.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. Loss [[ 0.16602299  0.05054328 -0.5936171 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 12/1000 [00:55<08:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. Loss [[ 0.1482994   0.03451752 -1.2342988 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 22/1000 [00:56<02:04,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 20. Loss [[ 0.13232887  0.04746087 -1.6516252 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 32/1000 [00:57<01:55,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 30. Loss [[ 0.13101256  0.05705051 -1.7908872 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 42/1000 [00:59<01:55,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 40. Loss [[ 0.13327396  0.05564924 -1.8461549 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 51/1000 [01:00<01:48,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 50. Loss [[ 0.13356082  0.06030494 -1.9167476 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 62/1000 [01:01<01:48,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 60. Loss [[ 0.13470314  0.05581608 -1.9245356 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 72/1000 [01:03<02:29,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 70. Loss [[ 0.13556312  0.0568357  -1.9789971 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 82/1000 [01:04<01:47,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. Loss [[ 0.13499326  0.06298901 -2.0649004 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 92/1000 [01:05<02:24,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 90. Loss [[ 0.13548733  0.06192218 -2.0910156 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 102/1000 [01:06<01:46,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 100. Loss [[ 0.13656764  0.05781668 -2.09869   ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 112/1000 [01:08<02:00,  7.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 110. Loss [[ 0.1364495   0.06392764 -2.1405923 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 122/1000 [01:09<01:46,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 120. Loss [[ 0.13648179  0.05689477 -2.150314  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 132/1000 [01:10<02:05,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 130. Loss [[ 0.13746746  0.05480615 -2.1705818 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 142/1000 [01:11<01:36,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 140. Loss [[ 0.13518779  0.08799879 -2.237619  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 152/1000 [01:13<01:54,  7.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 150. Loss [[ 0.14055721  0.04836968 -2.1625133 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 162/1000 [01:14<01:36,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 160. Loss [[ 0.13799451  0.0553973  -2.2239332 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 172/1000 [01:15<01:48,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 170. Loss [[ 0.13770932  0.06102269 -2.2786207 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 182/1000 [01:17<01:38,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 180. Loss [[ 0.13871138  0.0583611  -2.2941186 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 192/1000 [01:18<01:44,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 190. Loss [[ 0.13965869  0.05883147 -2.3011496 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 202/1000 [01:19<01:35,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 200. Loss [[ 0.13855083  0.05088525 -2.2363157 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 212/1000 [01:21<01:38,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 210. Loss [[ 0.15269892  0.08164361 -2.1422558 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 222/1000 [01:22<01:34,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 220. Loss [[ 0.13873509  0.06347071 -2.3034596 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 232/1000 [01:23<01:30,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 230. Loss [[ 0.13711408  0.06065069 -2.3299153 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 242/1000 [01:24<01:26,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 240. Loss [[ 0.13861461  0.05603258 -2.3367438 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 252/1000 [01:26<01:26,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 250. Loss [[ 0.13969073  0.05859392 -2.390268  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 262/1000 [01:27<01:25,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 260. Loss [[ 0.13900165  0.06401687 -2.4470735 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 272/1000 [01:28<01:29,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 270. Loss [[ 0.13905874  0.06550238 -2.4778252 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 282/1000 [01:30<01:58,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 280. Loss [[ 0.13944323  0.06550144 -2.499248  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 292/1000 [01:31<01:22,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 290. Loss [[ 0.13869293  0.10922603 -2.4779253 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 302/1000 [01:32<01:45,  6.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 300. Loss [[ 0.13990578  0.05522784 -2.4206536 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 312/1000 [01:33<01:24,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 310. Loss [[ 0.13848694  0.06941074 -2.5325818 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 322/1000 [01:35<01:35,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 320. Loss [[ 0.13941681  0.06262711 -2.544945  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 332/1000 [01:36<01:18,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 330. Loss [[ 0.13836561  0.06865465 -2.5919876 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 342/1000 [01:37<01:29,  7.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 340. Loss [[ 0.13801283  0.07631887 -2.625332  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 352/1000 [01:39<01:14,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 350. Loss [[ 0.13894704  0.07064427 -2.5969763 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 362/1000 [01:40<01:25,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 360. Loss [[ 0.13787495  0.07841527 -2.6573486 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 372/1000 [01:41<01:11,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 370. Loss [[ 0.1390403   0.06988269 -2.6075797 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 382/1000 [01:42<01:17,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 380. Loss [[ 0.13728459  0.07756513 -2.657591  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 392/1000 [01:44<01:12,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 390. Loss [[ 0.1388996   0.09305674 -2.617954  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 402/1000 [01:45<01:19,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 400. Loss [[ 0.13750744  0.08019252 -2.7011201 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 412/1000 [01:46<01:09,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 410. Loss [[ 0.14215636  0.07567875 -2.575374  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 422/1000 [01:48<01:11,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 420. Loss [[ 0.1374181   0.07296428 -2.6348112 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 432/1000 [01:49<01:06,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 430. Loss [[ 0.1403452   0.05947992 -2.5220132 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 442/1000 [01:50<01:06,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 440. Loss [[ 0.14147297  0.06528794 -2.6345932 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 451/1000 [01:51<01:05,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 450. Loss [[ 0.13842441  0.0778016  -2.708066  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 462/1000 [01:53<01:04,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 460. Loss [[ 0.1384667   0.07648575 -2.7127032 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 472/1000 [01:54<01:26,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 470. Loss [[ 0.13836499  0.07570591 -2.716914  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 482/1000 [01:55<01:03,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 480. Loss [[ 0.13863538  0.07479493 -2.717162  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 492/1000 [01:57<01:19,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 490. Loss [[ 0.13848184  0.07992317 -2.7416358 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 502/1000 [01:58<00:59,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 500. Loss [[ 0.13955565  0.0745853  -2.7063732 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 512/1000 [02:00<01:07,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 510. Loss [[ 0.13878062  0.07726494 -2.7417803 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 522/1000 [02:01<00:56,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 520. Loss [[ 0.13678919  0.0864385  -2.7541397 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 532/1000 [02:02<01:03,  7.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 530. Loss [[ 0.13878982  0.0826772  -2.742469  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 542/1000 [02:03<00:53,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 540. Loss [[ 0.13877034  0.08056661 -2.7539415 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 552/1000 [02:05<00:55,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 550. Loss [[ 0.13901971  0.07733846 -2.7399118 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 562/1000 [02:06<00:52,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 560. Loss [[ 0.1391309   0.07933976 -2.766006  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 572/1000 [02:07<00:54,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 570. Loss [[ 0.13874963  0.08518437 -2.7657533 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 582/1000 [02:08<00:50,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 580. Loss [[ 0.13935073  0.07678536 -2.7548714 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 592/1000 [02:10<00:50,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 590. Loss [[ 0.13854973  0.08448912 -2.778476  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 602/1000 [02:11<00:47,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 600. Loss [[ 0.13904911  0.07583625 -2.7496192 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 612/1000 [02:12<00:47,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 610. Loss [[ 0.13971153  0.07952867 -2.7315073 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 622/1000 [02:14<00:45,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 620. Loss [[ 0.13940383  0.0793879  -2.7637186 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 632/1000 [02:15<00:45,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 630. Loss [[ 0.13882555  0.07720488 -2.7680113 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 642/1000 [02:16<00:41,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 640. Loss [[ 0.13912906  0.08407456 -2.7841601 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 652/1000 [02:18<00:40,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 650. Loss [[ 0.13904835  0.08105709 -2.7969701 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 661/1000 [02:19<00:40,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 660. Loss [[ 0.13972485  0.07671014 -2.7565925 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 672/1000 [02:20<00:40,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 670. Loss [[ 0.13933115  0.08268024 -2.7877688 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 682/1000 [02:22<00:51,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 680. Loss [[ 0.13978341  0.07785592 -2.7850194 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 692/1000 [02:23<00:35,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 690. Loss [[ 0.1393278   0.07812784 -2.7902622 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 702/1000 [02:24<00:44,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 700. Loss [[ 0.13812084  0.0878529  -2.8306816 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 712/1000 [02:25<00:32,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 710. Loss [[ 0.13877898  0.08316281 -2.8254488 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 722/1000 [02:27<00:38,  7.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 720. Loss [[ 0.1398372   0.08554083 -2.7315583 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 732/1000 [02:28<00:32,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 730. Loss [[ 0.13829397  0.08420537 -2.820444  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 742/1000 [02:29<00:34,  7.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 740. Loss [[ 0.14168094  0.0656454  -2.6791801 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 752/1000 [02:30<00:29,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 750. Loss [[ 0.14326379  0.05845305 -2.608164  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 762/1000 [02:32<00:31,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 760. Loss [[ 0.13962686  0.07754825 -2.7915392 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 772/1000 [02:33<00:26,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 770. Loss [[ 0.1405774   0.07935918 -2.8110516 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 782/1000 [02:34<00:26,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 780. Loss [[ 0.14008379  0.07967756 -2.81382   ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 792/1000 [02:36<00:23,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 790. Loss [[ 0.13990243  0.07533818 -2.7972069 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 802/1000 [02:37<00:23,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 800. Loss [[ 0.13968295  0.0797355  -2.812569  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 812/1000 [02:38<00:21,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 810. Loss [[ 0.13986221  0.07669307 -2.8055549 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 822/1000 [02:39<00:21,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 820. Loss [[ 0.13919479  0.08626058 -2.8337018 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 832/1000 [02:41<00:20,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 830. Loss [[ 0.13982935  0.07750551 -2.809366  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 842/1000 [02:42<00:18,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 840. Loss [[ 0.13903259  0.08718287 -2.8486674 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 851/1000 [02:43<00:17,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 850. Loss [[ 0.14013761  0.0775475  -2.7924297 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 862/1000 [02:45<00:16,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 860. Loss [[ 0.13944228  0.07949068 -2.8287954 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 872/1000 [02:46<00:20,  6.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 870. Loss [[ 0.13942733  0.07997623 -2.8414915 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 882/1000 [02:47<00:14,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 880. Loss [[ 0.14054969  0.07834075 -2.776449  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 892/1000 [02:49<00:16,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 890. Loss [[ 0.1399905  0.0814425 -2.8022826]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 902/1000 [02:50<00:11,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 900. Loss [[ 0.14017157  0.09103542 -2.7733846 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 912/1000 [02:51<00:12,  7.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 910. Loss [[ 0.14028472  0.08187212 -2.798998  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 922/1000 [02:52<00:09,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 920. Loss [[ 0.13754424  0.09581524 -2.8645759 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 932/1000 [02:54<00:09,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 930. Loss [[ 0.14012553  0.07627413 -2.814789  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 942/1000 [02:55<00:06,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 940. Loss [[ 0.14059848  0.07254621 -2.7989054 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 952/1000 [02:56<00:06,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 950. Loss [[ 0.14019296  0.07470519 -2.8190868 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 962/1000 [02:57<00:04,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 960. Loss [[ 0.14008789  0.07680957 -2.8380532 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 972/1000 [02:59<00:03,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 970. Loss [[ 0.13951957  0.08041381 -2.8583262 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 982/1000 [03:00<00:02,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 980. Loss [[ 0.1397924  0.0789218 -2.843017 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 992/1000 [03:01<00:00,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 990. Loss [[ 0.13945502  0.0798228  -2.8566105 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:02<00:00,  5.48it/s]\n"
          ]
        }
      ],
      "source": [
        "def L_d(losses, params, state):\n",
        "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
        "    for i, (w, loss_func) in enumerate(losses):\n",
        "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
        "    return loss\n",
        "\n",
        "best = 1e6\n",
        "mu = 1\n",
        "alpha = 0.85\n",
        "for i in tqdm(range(n_iter)):\n",
        "    grads, cop_state = new_grad(params, cop_state, mu)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    mu = mu * alpha\n",
        "    loss = L_d(losses_eval, params, cop_state)\n",
        "    if not jnp.isnan(loss).any():\n",
        "        best_params = params\n",
        "        best_cop_state = cop_state\n",
        "        best = loss[0][-1]\n",
        "    else:\n",
        "        break\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print('Iter {}. Loss {}'.format(i, loss))\n",
        "\n",
        "# best_params = params\n",
        "# best_cop_state = cop_state\n",
        "# best = loss[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "id": "WTTpwjSAAgxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa01744-35b8-4c85-d3a6-1ba61eb2a482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.623769711388426e-71"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ex_M0 = TrainingTensors.UV_batches[:, 0, :].ravel()\n",
        "In_M0 = TrainingTensors.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "Ex_M1 = TrainingTensors.UV_batches[:, 1, :].ravel()\n",
        "In_M1 = TrainingTensors.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "Pr_M0 = nn_C(params, In_M0).ravel()\n",
        "Pr_M1 = nn_C(params, In_M1).ravel()\n",
        "\n",
        "plt.hist((Ex_M0 - Pr_M0) / Ex_M0, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "KfHQloco9FlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "f9c2e7af-b07f-4937-a930-a1cc383805fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.24344176, 0.31164743, 0.35991605, 0.40188877, 0.4386149 ,\n",
              "        0.47324239, 0.50682056, 0.54354669, 0.58656873, 1.        ]),\n",
              " array([-0.0030684 ,  0.09723677,  0.19754195,  0.29784712,  0.39815232,\n",
              "         0.49845749,  0.59876269,  0.69906783,  0.79937303,  0.89967817,\n",
              "         0.99998337]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist((Ex_M1 - Pr_M1) / Ex_M1, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "ci44OZkz9_vq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "ff4f62e5-39cf-4a8c-b8c8-8d20e750ca41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.17313746, 0.26232949, 0.33473242, 0.39979014, 0.45855194,\n",
              "        0.51311647, 0.56453305, 0.62434418, 0.7135362 , 1.        ]),\n",
              " array([-0.00146581,  0.09802247,  0.19751075,  0.29699901,  0.3964873 ,\n",
              "         0.49597558,  0.59546387,  0.69495213,  0.79444039,  0.89392871,\n",
              "         0.99341697]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX-VRCYivJC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a67029f-fcdb-4343-b336-c3f6fb9c8175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0062959073 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1d58ef50d380>:6: RuntimeWarning: invalid value encountered in log\n",
            "  yhat = -np.log(points_density)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.8285937"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLPnSwayvDYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0585837-a9ce-408d-88cf-d8733831ebe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.025396826 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-bf4ded0a2f4c>:7: RuntimeWarning: invalid value encountered in log\n",
            "  yhat = -np.log(points_density)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.6904744"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjKd8d6N2FpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42af3dae-65de-4011-d0c2-09098e76afa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.036906384,\n",
              " ConfidenceInterval(low=-1.762148334556642, high=-1.6165089896268123))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "res = bootstrap(yhat, np.nanmean)\n",
        "res.standard_error, res.confidence_interval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M0 - Pr_M0) / Ex_M0).mean()"
      ],
      "metadata": {
        "id": "Bf5LV4s0L_sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b266b94-59c9-42ca-c3c5-fd9c6eba42d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(57.306534, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M1 - Pr_M1) / Ex_M1).mean()"
      ],
      "metadata": {
        "id": "15kB3bZCAar1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca935ec4-261b-43a5-da08-c7022c3721cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(54.3662, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(jnp.abs(Ex_M0 - Pr_M0)).mean()"
      ],
      "metadata": {
        "id": "-KzqKEBcAc6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164152ec-14e4-4935-d779-1617943cbd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.17352444, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(jnp.abs(Ex_M1 - Pr_M1)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvab4B3dxDD6",
        "outputId": "19b2d02d-5957-4d56-cfa0-19d1b6a035ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.16961996, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}