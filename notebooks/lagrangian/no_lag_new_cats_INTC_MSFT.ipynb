{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0eenMXFTSO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LlGHCmorIVx",
        "outputId": "e4e106f2-fe8f-44a0-dd4f-49dacc3a34e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-33961236\n"
          ]
        }
      ],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsQWN3Qutf1",
        "outputId": "e978681f-ca19-4185-d607-88f4abbf2557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-wykumjk_\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-wykumjk_\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit c3850f012d0e128956573f7db0bacd8a12b84827\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from copulae==0.1)\n",
            "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
            "Collecting flake8 (from copulae==0.1)\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
            "Building wheels for collected packages: copulae\n",
            "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=8214ef2c17b04198d46b2b2ef04386523b59956351c40d85547a97278c076a18\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tkuedyey/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
            "Successfully built copulae\n",
            "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
            "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3GILjJgBkOT"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from copulae.training import setup_training\n",
        "from copulae.training.loss import sq_error\n",
        "from copulae.training.loss import sq_error_partial\n",
        "from copulae.training.loss import copula_likelihood\n",
        "\n",
        "from copulae.training.cflax.mono_aux import EluPOne\n",
        "\n",
        "from copulae.training.cflax.two_cats import FlexibleBi\n",
        "from copulae.training.cflax.two_cats import NormalBi\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "from copulae.training.cflax.two_cats import TransformLayer\n",
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "\n",
        "from copulae.typing import Tensor\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "\n",
        "import copy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import pandas as pd\n",
        "import scipy.stats as ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqYmiT-uvNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8o-Btitw9v"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59ZdlGCtyad"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDHMLIEptyc3"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmnDKhjxtyfK",
        "outputId": "bd10642e-93a8-4525-dac2-113fd1749726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gen-AC'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
            "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
            "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (466/466), 10.28 MiB | 12.53 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8rTp88Ityhd"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8liWvEt7wZBm"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2fnWDnywZEF"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA7CUNiQ_VF7"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoNLVJh9tyly"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrU2-FfguEXl"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yCf4X_muQBI"
      },
      "outputs": [],
      "source": [
        "losses = [\n",
        "    (0.01, sq_error),\n",
        "    (0.5, sq_error_partial),\n",
        "    (0.1, copula_likelihood),\n",
        "]\n",
        "lr = 2e-3\n",
        "n_iter = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmYBAhoVuExA"
      },
      "outputs": [],
      "source": [
        "losses_eval = [\n",
        "    (1.0, sq_error),\n",
        "    (1.0, sq_error_partial),\n",
        "    (1.0, copula_likelihood),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxPVIuCsugBt"
      },
      "outputs": [],
      "source": [
        "layer_widths = [128, 64, 32, 16]\n",
        "model = TwoCats(           # 2 Cats\n",
        "    [                      # Is a sequence of\n",
        "        TransformLayer(    # Monotonic Transforms\n",
        "            PositiveLayer(\n",
        "                #nn.Dense,\n",
        "                layer_widths,\n",
        "                EluPOne, EluPOne, EluPOne\n",
        "            ) # Defined by a positive NN\n",
        "        )\n",
        "    ],\n",
        "    FlexibleBi()           # Copulated with some bivariate CDF\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg99AIo7uKok"
      },
      "source": [
        "# Boston Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRJSg8VuLZc",
        "outputId": "08948fcc-07b8-49cc-ade7-5f1fcc5ee51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 955)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_loader = INTC_MSFT()\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lagrangian(params, cop_state, nn_C, nn_dC):\n",
        "    Ex_M0 = cop_state.UV_batches[:, 0, :].ravel()\n",
        "    In_M0 = cop_state.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "    Ex_M1 = cop_state.UV_batches[:, 1, :].ravel()\n",
        "    In_M1 = cop_state.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "    Pr_M0_H = nn_C(params, In_M0).ravel()\n",
        "    Pr_M1_H = nn_C(params, In_M1).ravel()\n",
        "\n",
        "    Pr_M0_dH = nn_dC(params, In_M0)[:, 1, :].ravel()\n",
        "    Pr_M1_dH = nn_dC(params, In_M1)[:, 0, :].ravel()\n",
        "\n",
        "    lag_0 = (Pr_M0_H - Ex_M0) * (Pr_M0_dH - 1)\n",
        "    lag_1 = (Pr_M1_H - Ex_M1) * (Pr_M1_dH - 1)\n",
        "\n",
        "    return (lag_0 + lag_1).mean()"
      ],
      "metadata": {
        "id": "JUtS9DAHIriV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b4JqYLueX4"
      },
      "outputs": [],
      "source": [
        "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
        "    model, TrainingTensors, losses, rescale=True\n",
        ")\n",
        "\n",
        "def new_forward(params, cop_state, penalty):\n",
        "    f =  forward(params, cop_state)\n",
        "    l =  f[0]\n",
        "    return l, f[1]\n",
        "\n",
        "new_grad = jax.grad(new_forward, has_aux=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTPcrb9uu3L8"
      },
      "outputs": [],
      "source": [
        "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
        "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
        "del subkey\n",
        "\n",
        "params = init_params\n",
        "optimizer = optax.adam(lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3UHmBVUu5O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb577860-dd54-4f83-b2b2-b2afb8896291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1000 [00:36<10:14:54, 36.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. Loss [[ 0.14638345  0.01145493 -0.08601899]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 12/1000 [00:56<08:11,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. Loss [[ 0.14254092  0.00734241 -0.17263688]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 22/1000 [00:57<02:24,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 20. Loss [[ 0.13918498  0.00736762 -0.23722087]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 32/1000 [00:58<01:56,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 30. Loss [[ 0.13933256  0.00784045 -0.25198886]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 42/1000 [01:00<02:07,  7.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 40. Loss [[ 0.13854906  0.00627178 -0.25539544]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 52/1000 [01:01<01:53,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 50. Loss [[ 0.13945591  0.00855475 -0.22972853]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 62/1000 [01:02<01:55,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 60. Loss [[ 0.13937457  0.00639778 -0.25160772]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 72/1000 [01:04<01:48,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 70. Loss [[ 0.13539691  0.01894626 -0.02121075]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 82/1000 [01:05<01:54,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. Loss [[ 0.1429892   0.00721828 -0.2010662 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 92/1000 [01:06<01:46,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 90. Loss [[ 0.14152417  0.00731692 -0.22548811]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 102/1000 [01:08<01:48,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 100. Loss [[ 0.13792679  0.00637147 -0.24381956]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 112/1000 [01:09<01:43,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 110. Loss [[ 0.137732    0.00631936 -0.2580467 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 122/1000 [01:10<01:43,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 120. Loss [[ 0.13888726  0.00595379 -0.2667716 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 131/1000 [01:11<01:41,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 130. Loss [[ 0.1388391   0.00536237 -0.27468383]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 142/1000 [01:13<01:47,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 140. Loss [[ 0.13876292  0.00518606 -0.27922156]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 152/1000 [01:14<02:23,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 150. Loss [[ 0.1395682   0.00483797 -0.28210896]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 162/1000 [01:15<01:41,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 160. Loss [[ 0.1397838   0.00441986 -0.2844586 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 172/1000 [01:17<02:05,  6.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 170. Loss [[ 0.1399484   0.00428206 -0.28699452]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 182/1000 [01:18<01:35,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 180. Loss [[ 0.14008701  0.00427171 -0.2899618 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 192/1000 [01:19<01:48,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 190. Loss [[ 0.13995813  0.00422076 -0.29230535]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 202/1000 [01:21<01:32,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 200. Loss [[ 0.14011602  0.00410279 -0.29406393]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 212/1000 [01:22<01:40,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 210. Loss [[ 0.14023167  0.00395836 -0.29557192]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 222/1000 [01:23<01:30,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 220. Loss [[ 0.14033307  0.00386001 -0.2974065 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 232/1000 [01:25<01:39,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 230. Loss [[ 0.1404356   0.0036945  -0.29919836]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 242/1000 [01:26<01:30,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 240. Loss [[ 0.14038822  0.00369437 -0.30143332]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 252/1000 [01:27<01:31,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 250. Loss [[ 0.14028734  0.00373147 -0.30364046]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 262/1000 [01:28<01:27,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 260. Loss [[ 0.14061072  0.00354548 -0.3045165 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 272/1000 [01:30<01:30,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 270. Loss [[ 0.14053857  0.0035431  -0.30619416]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 282/1000 [01:31<01:24,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 280. Loss [[ 0.14069267  0.00354586 -0.3074386 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 292/1000 [01:32<01:24,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 290. Loss [[ 0.14044598  0.00352337 -0.30867836]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 301/1000 [01:33<01:21,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 300. Loss [[ 0.14063174  0.00347292 -0.30968013]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 312/1000 [01:35<01:25,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 310. Loss [[ 0.14063743  0.00343826 -0.31064174]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 322/1000 [01:36<01:55,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 320. Loss [[ 0.14059854  0.00344718 -0.3113657 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 332/1000 [01:38<01:19,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 330. Loss [[ 0.1404383   0.00354991 -0.31258798]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 342/1000 [01:39<01:48,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 340. Loss [[ 0.14046764  0.00364422 -0.3127474 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 352/1000 [01:40<01:16,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 350. Loss [[ 0.1404539   0.00343804 -0.31482518]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 362/1000 [01:41<01:30,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 360. Loss [[ 0.14114213  0.00337783 -0.31437576]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 372/1000 [01:43<01:13,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 370. Loss [[ 0.14049348  0.00328264 -0.31526875]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 382/1000 [01:44<01:20,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 380. Loss [[ 0.14072128  0.00339947 -0.31686372]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 392/1000 [01:45<01:10,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 390. Loss [[ 0.14058912  0.00329865 -0.31767124]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 402/1000 [01:47<01:16,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 400. Loss [[ 0.14125358  0.00382365 -0.3117182 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 412/1000 [01:48<01:11,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 410. Loss [[ 0.14026487  0.00341786 -0.31763253]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 422/1000 [01:49<01:14,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 420. Loss [[ 0.14082016  0.00322731 -0.31849772]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 432/1000 [01:50<01:10,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 430. Loss [[ 0.14065295  0.00327572 -0.3194589 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 442/1000 [01:52<01:11,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 440. Loss [[ 0.14041662  0.0032776  -0.3202956 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 452/1000 [01:53<01:06,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 450. Loss [[ 0.14036317  0.00333231 -0.32097483]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 462/1000 [01:54<01:06,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 460. Loss [[ 0.1402029   0.00327573 -0.32167926]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 471/1000 [01:56<01:03,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 470. Loss [[ 0.14015843  0.00322581 -0.32264975]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 482/1000 [01:57<01:03,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 480. Loss [[ 0.1402051   0.00316743 -0.322904  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 492/1000 [01:59<01:25,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 490. Loss [[ 0.14003307  0.00324408 -0.3241705 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 502/1000 [02:00<01:02,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 500. Loss [[ 0.14061667  0.00358083 -0.3193151 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 512/1000 [02:01<01:13,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 510. Loss [[ 0.14001037  0.00336729 -0.32293433]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 522/1000 [02:02<00:57,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 520. Loss [[ 0.14033844  0.00319982 -0.32547903]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 532/1000 [02:04<01:04,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 530. Loss [[ 0.14032051  0.00316088 -0.32615462]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 542/1000 [02:05<00:52,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 540. Loss [[ 0.14007604  0.00326086 -0.32654783]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 552/1000 [02:06<00:57,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 550. Loss [[ 0.14033632  0.00310878 -0.3264642 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 562/1000 [02:07<00:50,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 560. Loss [[ 0.14089386  0.00332002 -0.32524785]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 572/1000 [02:09<00:55,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 570. Loss [[ 0.14010707  0.00348607 -0.32480666]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 582/1000 [02:10<00:49,  8.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 580. Loss [[ 0.14017116  0.00326224 -0.32664058]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 592/1000 [02:11<00:53,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 590. Loss [[ 0.14021242  0.00314297 -0.32751182]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 602/1000 [02:13<00:47,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 600. Loss [[ 0.13989666  0.00322931 -0.3279973 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 612/1000 [02:14<00:47,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 610. Loss [[ 0.1402833   0.00313492 -0.32828683]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 622/1000 [02:15<00:43,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 620. Loss [[ 0.14022367  0.00306372 -0.3286391 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 632/1000 [02:16<00:43,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 630. Loss [[ 0.13995397  0.00313375 -0.32872105]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 642/1000 [02:18<00:40,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 640. Loss [[ 0.13993755  0.00322251 -0.32885218]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 652/1000 [02:19<00:40,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 650. Loss [[ 0.1401861   0.00309785 -0.32939333]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 661/1000 [02:20<00:38,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 660. Loss [[ 0.14015363  0.00321316 -0.32906386]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 672/1000 [02:21<00:38,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 670. Loss [[ 0.14002506  0.00331556 -0.32909107]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 682/1000 [02:23<00:52,  6.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 680. Loss [[ 0.14014225  0.00309009 -0.32934707]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 692/1000 [02:24<00:36,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 690. Loss [[ 0.14002171  0.00317856 -0.3300088 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 702/1000 [02:25<00:49,  5.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 700. Loss [[ 0.14033939  0.0029797  -0.32973135]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 712/1000 [02:27<00:33,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 710. Loss [[ 0.14081363  0.00314197 -0.32823008]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 722/1000 [02:28<00:41,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 720. Loss [[ 0.14065127  0.00298622 -0.33030462]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 732/1000 [02:29<00:30,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 730. Loss [[ 0.14017275  0.003129   -0.3309162 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 742/1000 [02:31<00:36,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 740. Loss [[ 0.14037287  0.0030355  -0.33118555]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 752/1000 [02:32<00:28,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 750. Loss [[ 0.14048216  0.00339686 -0.32822922]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 762/1000 [02:33<00:30,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 760. Loss [[ 0.13953206  0.00313239 -0.33043116]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 772/1000 [02:34<00:26,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 770. Loss [[ 0.13979223  0.00315637 -0.33060908]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 782/1000 [02:36<00:28,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 780. Loss [[ 0.14049798  0.00338254 -0.3291603 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 792/1000 [02:37<00:24,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 790. Loss [[ 0.13986145  0.00320178 -0.33038452]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 802/1000 [02:38<00:24,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 800. Loss [[ 0.14009015  0.00309457 -0.33292913]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 812/1000 [02:39<00:21,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 810. Loss [[ 0.1399241   0.00331638 -0.33234793]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 822/1000 [02:41<00:21,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 820. Loss [[ 0.14027779  0.00307068 -0.33437794]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 832/1000 [02:42<00:19,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 830. Loss [[ 0.13927703  0.0044171  -0.32341975]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 842/1000 [02:43<00:19,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 840. Loss [[ 0.14187483  0.00318553 -0.31914046]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 852/1000 [02:44<00:17,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 850. Loss [[ 0.14004532  0.00363121 -0.3154684 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 862/1000 [02:46<00:16,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 860. Loss [[ 0.14008756  0.00308716 -0.3199229 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 871/1000 [02:47<00:14,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 870. Loss [[ 0.14003691  0.003041   -0.32168972]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 882/1000 [02:48<00:13,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 880. Loss [[ 0.14070646  0.00294039 -0.3228222 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 892/1000 [02:50<00:17,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 890. Loss [[ 0.14041016  0.00285703 -0.32333225]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 902/1000 [02:51<00:11,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 900. Loss [[ 0.14030091  0.0028589  -0.3239908 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 912/1000 [02:52<00:13,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 910. Loss [[ 0.14043684  0.00286466 -0.32462132]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 922/1000 [02:53<00:09,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 920. Loss [[ 0.14037165  0.00291655 -0.32547528]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 932/1000 [02:55<00:09,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 930. Loss [[ 0.1403095   0.00301254 -0.3291346 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 942/1000 [02:56<00:06,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 940. Loss [[ 0.14053898  0.00287502 -0.33121574]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 952/1000 [02:57<00:06,  7.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 950. Loss [[ 0.14027543  0.00298644 -0.33282617]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 962/1000 [02:59<00:04,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 960. Loss [[ 0.14017951  0.00296135 -0.33346784]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 972/1000 [03:00<00:03,  7.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 970. Loss [[ 0.14032748  0.00297492 -0.33419034]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 982/1000 [03:01<00:02,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 980. Loss [[ 0.14039513  0.00296933 -0.3346552 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 992/1000 [03:03<00:01,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 990. Loss [[ 0.14038272  0.00296517 -0.33504865]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:04<00:00,  5.43it/s]\n"
          ]
        }
      ],
      "source": [
        "def L_d(losses, params, state):\n",
        "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
        "    for i, (w, loss_func) in enumerate(losses):\n",
        "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
        "    return loss\n",
        "\n",
        "best = 1e6\n",
        "mu = 1\n",
        "alpha = 0.95\n",
        "# penalty = 1.0\n",
        "for i in tqdm(range(n_iter)):\n",
        "    grads, cop_state = new_grad(params, cop_state, mu)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    mu = mu * alpha\n",
        "    # penalty += 0.01 * penalty\n",
        "    loss = L_d(losses_eval, params, cop_state)\n",
        "    if not jnp.isnan(loss).any():\n",
        "        best_params = params\n",
        "        best_cop_state = cop_state\n",
        "        best = loss[0][-1]\n",
        "    else:\n",
        "        break\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print('Iter {}. Loss {}'.format(i, loss))\n",
        "\n",
        "# best_params = params\n",
        "# best_cop_state = cop_state\n",
        "# best = loss[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ex_M0 = TrainingTensors.UV_batches[:, 0, :].ravel()\n",
        "In_M0 = TrainingTensors.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "Ex_M1 = TrainingTensors.UV_batches[:, 1, :].ravel()\n",
        "In_M1 = TrainingTensors.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "Pr_M0 = nn_C(params, In_M0).ravel()\n",
        "Pr_M1 = nn_C(params, In_M1).ravel()\n",
        "\n",
        "plt.hist((Ex_M0 - Pr_M0) / Ex_M0, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "KfHQloco9FlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "b1abb998-1bc1-42e4-c039-6e43ce31c4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.66492145, 0.75706805, 0.83246072, 0.89005234, 0.93298428,\n",
              "        0.96335077, 0.98219894, 0.99267014, 0.99790574, 0.99999998]),\n",
              " array([-0.00339917,  0.03417924,  0.07175764,  0.10933604,  0.14691444,\n",
              "         0.18449284,  0.22207125,  0.25964963,  0.29722804,  0.33480644,\n",
              "         0.37238485]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist((Ex_M1 - Pr_M1) / Ex_M1, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "ci44OZkz9_vq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "0a224a7b-e34d-4b87-a747-a2e7997d5888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.70575913, 0.81884814, 0.88795809, 0.93298426, 0.96125652,\n",
              "        0.97905756, 0.98952877, 0.99476437, 0.99790573, 0.99999997]),\n",
              " array([-0.00952038,  0.03544276,  0.0804059 ,  0.12536903,  0.17033216,\n",
              "         0.2152953 ,  0.26025844,  0.30522159,  0.35018471,  0.39514786,\n",
              "         0.44011098]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX-VRCYivJC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0add32-e325-4679-db17-625ce474c141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.09452453"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLPnSwayvDYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c11edb6-1644-47cc-c60d-1511046465ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.043706305"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjKd8d6N2FpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceee34f7-c311-4cae-ad8b-3a2249353393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.033252716,\n",
              " ConfidenceInterval(low=-0.1050268475984551, high=0.026477400591834836))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "res = bootstrap(yhat, np.nanmean)\n",
        "res.standard_error, res.confidence_interval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M1 - Pr_M1) / Ex_M1).mean()"
      ],
      "metadata": {
        "id": "Bf5LV4s0L_sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f1289c-cd56-4dd1-c6a6-6cee88ffe920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(4.1520824, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M0 - Pr_M0) / Ex_M0).mean()"
      ],
      "metadata": {
        "id": "g6QkhTQFAUOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e653842-4e83-4ba4-f28f-df1826469709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(4.56957, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(jnp.abs(Ex_M0 - Pr_M0)).mean()"
      ],
      "metadata": {
        "id": "uh0doHfMAV_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f60bcfe-1692-41dd-97e3-671ff9577fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.00673158, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(jnp.abs(Ex_M0 - Pr_M0)).mean()"
      ],
      "metadata": {
        "id": "J9SKlGiy3InN",
        "outputId": "d5385eb3-6e0c-4afc-f29d-1a06235a697d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.00673158, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymba-XiR3J1U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}