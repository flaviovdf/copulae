{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0eenMXFTSO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LlGHCmorIVx",
        "outputId": "1bd78c07-c2af-49e0-ce1c-21af61a45f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-33961236\n"
          ]
        }
      ],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsQWN3Qutf1",
        "outputId": "959e4d79-bcf3-4bfe-c2a1-056e991cbac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-o9p_jj5t\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-o9p_jj5t\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit 006a8cdf39eadae9803918962d9b6f3443327ecf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from copulae==0.1)\n",
            "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
            "Collecting flake8 (from copulae==0.1)\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
            "Building wheels for collected packages: copulae\n",
            "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=c35d4379ed2e7b528d73069ff062f590f409ab930ff92b7c0e091a1532697550\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d_pwa999/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
            "Successfully built copulae\n",
            "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
            "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3GILjJgBkOT"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from copulae.training import setup_training\n",
        "from copulae.training.loss import sq_error\n",
        "from copulae.training.loss import sq_error_partial\n",
        "from copulae.training.loss import copula_likelihood\n",
        "\n",
        "from copulae.training.cflax.mono_aux import EluPOne\n",
        "\n",
        "from copulae.training.cflax.two_cats import FlexibleBi\n",
        "from copulae.training.cflax.two_cats import NormalBi\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "from copulae.training.cflax.two_cats import TransformLayer\n",
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "\n",
        "from copulae.typing import Tensor\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "\n",
        "import copy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import pandas as pd\n",
        "import scipy.stats as ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqYmiT-uvNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8o-Btitw9v"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59ZdlGCtyad"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDHMLIEptyc3"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmnDKhjxtyfK",
        "outputId": "7a65e0b2-428d-478e-8bbd-fd6081f3bdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gen-AC'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
            "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
            "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (466/466), 10.28 MiB | 16.60 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8rTp88Ityhd"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8liWvEt7wZBm"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2fnWDnywZEF"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA7CUNiQ_VF7"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoNLVJh9tyly"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Code"
      ],
      "metadata": {
        "id": "aSqU3TijitqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf8\n",
        "\n",
        "\n",
        "from flax.linen.dtypes import promote_dtype\n",
        "\n",
        "from flax.typing import (\n",
        "    Array,\n",
        "    Dtype,\n",
        "    Initializer,\n",
        "    Optional,\n",
        "    PrecisionLike\n",
        ")\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "lecun_normal = nn.initializers.lecun_normal()\n",
        "zeros_init = nn.initializers.zeros_init()\n",
        "ones_init = nn.initializers.ones_init()\n",
        "\n",
        "\n",
        "class PositiveDense(nn.Module):\n",
        "    \"\"\"A linear with transformation *positive weights*\n",
        "    applied over the last dimension of the input.\n",
        "\n",
        "    Positive weights are simply the regular Dense layer\n",
        "    weights re-scaled by a elu(w) + 1 activation.\n",
        "\n",
        "    Follows the same approach as `flax.linen.linear.Dense`.\n",
        "    Check that documentation for more information.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    features: the number of output features.\n",
        "    use_bias: whether to add a bias to the output\n",
        "        (default: True).\n",
        "    dtype: the dtype of the computation\n",
        "        (default: infer from input and params).\n",
        "    param_dtype: the dtype passed to parameter initializers\n",
        "        (default: float32).\n",
        "    precision: numerical precision of the computation see\n",
        "        ``jax.lax.Precision`` for details.\n",
        "    kernel_init: initializer function for the weight\n",
        "        matrix.\n",
        "    bias_init: initializer function for the bias.\n",
        "    \"\"\"\n",
        "\n",
        "    features: int\n",
        "    use_bias: bool = True\n",
        "    dtype: Optional[Dtype] = None\n",
        "    param_dtype: Dtype = jnp.float32\n",
        "    precision: PrecisionLike = None\n",
        "    kernel_init: Initializer = zeros_init\n",
        "    bias_init: Initializer = zeros_init\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs: Array) -> Array:\n",
        "        \"\"\"Applies a linear transformation with positive\n",
        "        weights to the inputs along the last dimension.\n",
        "\n",
        "        Args:\n",
        "            inputs: The nd-array to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            The transformed input.\n",
        "        \"\"\"\n",
        "        kernel = self.param(\n",
        "            'kernel',\n",
        "            self.kernel_init,\n",
        "            (jnp.shape(inputs)[-1], self.features),\n",
        "            self.param_dtype,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            bias = self.param(\n",
        "                'bias', self.bias_init,\n",
        "                (self.features,),\n",
        "                self.param_dtype\n",
        "            )\n",
        "        else:\n",
        "            bias = None\n",
        "        inputs, kernel, bias = promote_dtype(\n",
        "            inputs, kernel, bias, dtype=self.dtype\n",
        "        )\n",
        "        kernel = nn.elu(kernel) + 1\n",
        "\n",
        "        dot_general = jax.lax.dot_general\n",
        "        y = dot_general(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            (((inputs.ndim - 1,), (0,)), ((), ())),\n",
        "            precision=self.precision,\n",
        "        )\n",
        "        if bias is not None:\n",
        "            y += jnp.reshape(\n",
        "                bias, (1,) * (y.ndim - 1) + (-1,)\n",
        "            )\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "aTPgFBfPkMT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "\n",
        "\n",
        "from typing import Sequence\n",
        "from jax.scipy.special import ndtri\n",
        "\n",
        "\n",
        "class PositiveLayerNew(nn.Module):\n",
        "    # dense: nn.Dense | PositiveDense\n",
        "    layers: Sequence[int]\n",
        "    # ini: EluPOne | SoftPlus | Identity\n",
        "    # mid: EluPOne | SoftPlus | ResELUPlusOne | ResSoftPlus\n",
        "    # end: EluPOne | SoftPlus | ResELUPlusOne | ResSoftPlus\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, U: Tensor) -> Tensor:\n",
        "        a = jnp.clip(U.T, 0, 1)\n",
        "        z = PositiveDense(self.layers[0])(a)\n",
        "        a = nn.elu(z) + 1\n",
        "\n",
        "        for layer_width in self.layers[1:]:\n",
        "            z = PositiveDense(layer_width)(a)\n",
        "            a = nn.elu(z) + 1\n",
        "\n",
        "        z = PositiveDense(1)(a)\n",
        "        return nn.elu(z) + 1\n",
        "\n",
        "\n",
        "class TwoCatsNew(nn.Module):\n",
        "    base: Sequence[TransformLayer]\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, U: Tensor) -> Tensor:\n",
        "        Z = U\n",
        "        for pl in self.base:\n",
        "            Z = pl(U)\n",
        "\n",
        "        z0 = Z[0]\n",
        "        z1 = Z[1]\n",
        "\n",
        "        x0 = ndtri(z0)\n",
        "        x1 = ndtri(z1)\n",
        "\n",
        "        return NormalBi()(x0, x1)"
      ],
      "metadata": {
        "id": "Q2RldqAKiwNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrU2-FfguEXl"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yCf4X_muQBI"
      },
      "outputs": [],
      "source": [
        "losses = [\n",
        "    (0.01, sq_error),\n",
        "    (0.5, sq_error_partial),\n",
        "    (0.1, copula_likelihood),\n",
        "]\n",
        "lr = 2e-2\n",
        "n_iter = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmYBAhoVuExA"
      },
      "outputs": [],
      "source": [
        "losses_eval = [\n",
        "    (1.0, sq_error),\n",
        "    (1.0, sq_error_partial),\n",
        "    (1.0, copula_likelihood),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxPVIuCsugBt"
      },
      "outputs": [],
      "source": [
        "layer_widths = [128, 64, 32, 16]\n",
        "model = TwoCats(           # 2 Cats\n",
        "    [                      # Is a sequence of\n",
        "        TransformLayer(    # Monotonic Transforms\n",
        "            PositiveLayer(\n",
        "                #nn.Dense,\n",
        "                layer_widths,\n",
        "                EluPOne, EluPOne, EluPOne\n",
        "            ) # Defined by a positive NN\n",
        "        )\n",
        "    ],\n",
        "    FlexibleBi()           # Copulated with some bivariate CDF\n",
        "  )\n",
        "\n",
        "# layer_widths = [128, 64, 32, 16]\n",
        "# model = TwoCatsNew(           # 2 Cats\n",
        "#     [                      # Is a sequence of\n",
        "#         TransformLayer(    # Monotonic Transforms\n",
        "#             PositiveLayerNew(\n",
        "#                 layer_widths,\n",
        "#             )\n",
        "#         )\n",
        "#     ]\n",
        "#   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg99AIo7uKok"
      },
      "source": [
        "# Boston Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRJSg8VuLZc",
        "outputId": "a25b76dd-01ba-4d25-8edf-1f21f76f3910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 955)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data_loader = INTC_MSFT()\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lagrangian(params, cop_state, nn_C, nn_dC):\n",
        "    Ex_M0 = cop_state.UV_batches[:, 0, :].ravel()\n",
        "    In_M0 = cop_state.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "    Ex_M1 = cop_state.UV_batches[:, 1, :].ravel()\n",
        "    In_M1 = cop_state.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "    Pr_M0_H = nn_C(params, In_M0).ravel()\n",
        "    Pr_M1_H = nn_C(params, In_M1).ravel()\n",
        "\n",
        "    Pr_M0_dH = nn_dC(params, In_M0)[:, 1, :].ravel()\n",
        "    Pr_M1_dH = nn_dC(params, In_M1)[:, 0, :].ravel()\n",
        "\n",
        "    lag_0 = (Pr_M0_H - Ex_M0) * (Pr_M0_dH - 1)\n",
        "    lag_1 = (Pr_M1_H - Ex_M1) * (Pr_M1_dH - 1)\n",
        "\n",
        "    return (lag_0 + lag_1).mean()"
      ],
      "metadata": {
        "id": "JUtS9DAHIriV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b4JqYLueX4"
      },
      "outputs": [],
      "source": [
        "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
        "    model, TrainingTensors, losses, rescale=True\n",
        ")\n",
        "\n",
        "def new_forward(params, cop_state, penalty):\n",
        "    f =  forward(params, cop_state)\n",
        "    l =  penalty * f[0]\n",
        "    l += lagrangian(params, cop_state, nn_C, nn_dC)\n",
        "    return l, f[1]\n",
        "\n",
        "new_grad = jax.grad(new_forward, has_aux=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTPcrb9uu3L8"
      },
      "outputs": [],
      "source": [
        "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
        "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
        "del subkey\n",
        "\n",
        "params = init_params\n",
        "optimizer = optax.adam(lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3UHmBVUu5O-",
        "outputId": "e5ef886f-8dc1-49d0-e8a2-b5cb7ac6a538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/500 [00:49<6:49:38, 49.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. Loss [[ 0.14638345  0.01145493 -0.08601899]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 11/500 [01:09<07:09,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. Loss [[ 0.13520043  0.01029394 -0.21201856]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 21/500 [01:12<01:57,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 20. Loss [[ 0.13528974  0.00851271 -0.25608352]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 32/500 [01:14<01:41,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 30. Loss [[ 0.1355736   0.00787883 -0.27678743]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 41/500 [01:16<01:43,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 40. Loss [[ 0.13678277  0.00637179 -0.28171024]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 51/500 [01:19<01:39,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 50. Loss [[ 0.13707347  0.00595897 -0.2830791 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 61/500 [01:21<01:42,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 60. Loss [[ 0.13716488  0.00580723 -0.28468835]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 71/500 [01:23<01:37,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 70. Loss [[ 0.13719115  0.00575631 -0.28540438]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 81/500 [01:26<01:39,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. Loss [[ 0.13719967  0.00573569 -0.28569478]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 91/500 [01:28<01:31,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 90. Loss [[ 0.13719697  0.00572938 -0.28582317]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 101/500 [01:30<01:28,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 100. Loss [[ 0.13724624  0.00569942 -0.28565073]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 111/500 [01:33<01:31,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 110. Loss [[ 0.13729726  0.00566869 -0.2854164 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 121/500 [01:35<01:32,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 120. Loss [[ 0.13730985  0.00565819 -0.28536144]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 131/500 [01:37<01:24,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 130. Loss [[ 0.13730055  0.00566091 -0.28541696]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 141/500 [01:40<01:23,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 140. Loss [[ 0.13733041  0.00564083 -0.28528035]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 151/500 [01:42<01:20,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 150. Loss [[ 0.13736065  0.00562123 -0.2851568 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 161/500 [01:44<01:21,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 160. Loss [[ 0.1373804   0.00560531 -0.2850468 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 171/500 [01:47<01:22,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 170. Loss [[ 0.13742505  0.00557604 -0.2848183 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 181/500 [01:49<01:17,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 180. Loss [[ 0.13749018  0.00553709 -0.28449225]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 191/500 [01:51<01:15,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 190. Loss [[ 0.13751157  0.00552115 -0.2843793 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 201/500 [01:54<01:17,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 200. Loss [[ 0.13752535  0.00550818 -0.28429824]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 211/500 [01:56<01:14,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 210. Loss [[ 0.13758875  0.00547467 -0.2839966 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 221/500 [01:58<01:13,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 220. Loss [[ 0.13764872  0.00544489 -0.2836851 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 231/500 [02:01<01:10,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 230. Loss [[ 0.1376889  0.0054248 -0.2834963]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 241/500 [02:03<01:08,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 240. Loss [[ 0.13769417  0.00542079 -0.28345224]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 251/500 [02:05<01:05,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 250. Loss [[ 0.13763647  0.00544605 -0.28377405]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 261/500 [02:08<01:08,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 260. Loss [[ 0.13761671  0.00545318 -0.28388366]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 271/500 [02:10<01:04,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 270. Loss [[ 0.13762435  0.00544621 -0.2838526 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 281/500 [02:12<00:46,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 280. Loss [[ 0.13768911  0.00541505 -0.2835418 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 291/500 [02:15<00:43,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 290. Loss [[ 0.13772507  0.00539612 -0.28338125]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 301/500 [02:17<00:41,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 300. Loss [[ 0.13774444  0.00538992 -0.28329608]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 311/500 [02:19<00:41,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 310. Loss [[ 0.13778786  0.00537174 -0.28302267]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 321/500 [02:22<00:37,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 320. Loss [[ 0.13779746  0.00537142 -0.28297305]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 331/500 [02:24<00:35,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 330. Loss [[ 0.1378796   0.00534201 -0.28246096]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 341/500 [02:26<00:33,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 340. Loss [[ 0.13790059  0.00533403 -0.282303  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 351/500 [02:28<00:31,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 350. Loss [[ 0.1378651   0.00534574 -0.2825168 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 361/500 [02:31<00:29,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 360. Loss [[ 0.13786483  0.00534095 -0.2825205 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 371/500 [02:33<00:26,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 370. Loss [[ 0.13785051  0.00534531 -0.28259254]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 381/500 [02:35<00:24,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 380. Loss [[ 0.13789399  0.00532987 -0.28230006]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 391/500 [02:38<00:23,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 390. Loss [[ 0.13792984  0.00531133 -0.28209946]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 401/500 [02:40<00:21,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 400. Loss [[ 0.13800235  0.00527743 -0.2816729 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 411/500 [02:42<00:19,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 410. Loss [[ 0.13807775  0.00524982 -0.28125423]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 421/500 [02:45<00:17,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 420. Loss [[ 0.13812903  0.00523011 -0.28093293]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 431/500 [02:47<00:14,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 430. Loss [[ 0.13819206  0.00520813 -0.2805691 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 441/500 [02:49<00:12,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 440. Loss [[ 0.13821682  0.0051997  -0.2803881 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 451/500 [02:52<00:10,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 450. Loss [[ 0.1382042   0.00520323 -0.2804643 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 461/500 [02:54<00:08,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 460. Loss [[ 0.13823308  0.0051967  -0.28022668]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 471/500 [02:56<00:06,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 470. Loss [[ 0.13826115  0.00519055 -0.28005236]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 481/500 [02:59<00:04,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 480. Loss [[ 0.13830335  0.00517969 -0.2797406 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 491/500 [03:01<00:01,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 490. Loss [[ 0.13829462  0.00518509 -0.27979127]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [03:03<00:00,  2.72it/s]\n"
          ]
        }
      ],
      "source": [
        "def L_d(losses, params, state):\n",
        "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
        "    for i, (w, loss_func) in enumerate(losses):\n",
        "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
        "    return loss\n",
        "\n",
        "best = 1e6\n",
        "mu = 1\n",
        "alpha = 0.85\n",
        "# penalty = 1.0\n",
        "for i in tqdm(range(n_iter)):\n",
        "    grads, cop_state = new_grad(params, cop_state, mu)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    mu = mu * alpha\n",
        "    # penalty += 0.01 * penalty\n",
        "    loss = L_d(losses_eval, params, cop_state)\n",
        "    if not jnp.isnan(loss).any():\n",
        "        best_params = params\n",
        "        best_cop_state = cop_state\n",
        "        best = loss[0][-1]\n",
        "    else:\n",
        "        break\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print('Iter {}. Loss {}'.format(i, loss))\n",
        "\n",
        "# best_params = params\n",
        "# best_cop_state = cop_state\n",
        "# best = loss[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ex_M0 = TrainingTensors.UV_batches[:, 0, :].ravel()\n",
        "In_M0 = TrainingTensors.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "Ex_M1 = TrainingTensors.UV_batches[:, 1, :].ravel()\n",
        "In_M1 = TrainingTensors.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "Pr_M0 = nn_C(params, In_M0).ravel()\n",
        "Pr_M1 = nn_C(params, In_M1).ravel()\n",
        "\n",
        "plt.hist((Ex_M0 - Pr_M0) / Ex_M0, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "KfHQloco9FlR",
        "outputId": "a6898eab-1b0e-405c-e261-e0c7cf418d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00104712, 0.00314136, 0.0052356 , 0.0104712 , 0.01884817,\n",
              "        0.03455497, 0.06387435, 0.11518325, 0.21465969, 1.00000003]),\n",
              " array([-0.27727652, -0.24775501, -0.2182335 , -0.18871199, -0.15919048,\n",
              "        -0.12966897, -0.10014745, -0.07062594, -0.04110442, -0.01158291,\n",
              "         0.0179386 ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist((Ex_M1 - Pr_M1) / Ex_M1, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "ci44OZkz9_vq",
        "outputId": "f7a1ed9c-8cb4-468e-d4c5-3b0cae802b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00104712, 0.00314136, 0.0052356 , 0.0104712 , 0.01884817,\n",
              "        0.03350785, 0.05863874, 0.10052356, 0.17696335, 1.        ]),\n",
              " array([-0.18196335, -0.16238661, -0.14280988, -0.12323315, -0.10365641,\n",
              "        -0.08407968, -0.06450294, -0.0449262 , -0.02534947, -0.00577273,\n",
              "         0.013804  ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX-VRCYivJC2",
        "outputId": "b249657a-284d-4eb5-c40a-44f61f4770e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.053261433"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLPnSwayvDYV",
        "outputId": "e243e34b-6b95-4c04-9c02-bee14b46f2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.02970626"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjKd8d6N2FpH",
        "outputId": "4e3e5985-b931-47a4-9783-bf33dd1fe8d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0343882,\n",
              " ConfidenceInterval(low=-0.09340936051177985, high=0.043368525160884644))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "res = bootstrap(yhat, np.nanmean)\n",
        "res.standard_error, res.confidence_interval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M1 - Pr_M1) / Ex_M1).mean()"
      ],
      "metadata": {
        "id": "Bf5LV4s0L_sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8810776-f3de-4b58-8a50-8450f924f1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(1.5214118, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M0 - Pr_M0) / Ex_M0).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6QkhTQFAUOj",
        "outputId": "9816a5a3-a287-4f97-9e04-06d45e8a2800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(2.2372382, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uh0doHfMAV_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}