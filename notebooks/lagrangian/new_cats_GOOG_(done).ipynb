{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0eenMXFTSO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LlGHCmorIVx",
        "outputId": "d608bb21-3966-493a-e358-950d3f0d6170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-33961236\n"
          ]
        }
      ],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsQWN3Qutf1",
        "outputId": "7a8099e6-21af-4ef4-951a-d5a0edf33a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-ktlqp059\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-ktlqp059\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit c3850f012d0e128956573f7db0bacd8a12b84827\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from copulae==0.1)\n",
            "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
            "Collecting flake8 (from copulae==0.1)\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
            "Building wheels for collected packages: copulae\n",
            "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=cb0fbc2cada6ea0b9109dc0a737f19ffe923f525c7320f9f838a7f5854d01b7d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-07rttdyh/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
            "Successfully built copulae\n",
            "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
            "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3GILjJgBkOT"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from copulae.training import setup_training\n",
        "from copulae.training.loss import sq_error\n",
        "from copulae.training.loss import sq_error_partial\n",
        "from copulae.training.loss import copula_likelihood\n",
        "\n",
        "from copulae.training.cflax.mono_aux import EluPOne\n",
        "\n",
        "from copulae.training.cflax.two_cats import FlexibleBi\n",
        "from copulae.training.cflax.two_cats import NormalBi\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "from copulae.training.cflax.two_cats import TransformLayer\n",
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "\n",
        "from copulae.typing import Tensor\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "\n",
        "import copy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import pandas as pd\n",
        "import scipy.stats as ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqYmiT-uvNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8o-Btitw9v"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59ZdlGCtyad"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDHMLIEptyc3"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmnDKhjxtyfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a294cfb-bcac-4419-e644-14b01cb6c16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gen-AC'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
            "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
            "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (466/466), 10.28 MiB | 10.76 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8rTp88Ityhd"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8liWvEt7wZBm"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2fnWDnywZEF"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA7CUNiQ_VF7"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoNLVJh9tyly"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrU2-FfguEXl"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yCf4X_muQBI"
      },
      "outputs": [],
      "source": [
        "losses = [\n",
        "    (0.01, sq_error),\n",
        "    (0.5, sq_error_partial),\n",
        "    (0.1, copula_likelihood),\n",
        "]\n",
        "lr = 2e-3\n",
        "n_iter = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmYBAhoVuExA"
      },
      "outputs": [],
      "source": [
        "losses_eval = [\n",
        "    (1.0, sq_error),\n",
        "    (1.0, sq_error_partial),\n",
        "    (1.0, copula_likelihood),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxPVIuCsugBt"
      },
      "outputs": [],
      "source": [
        "layer_widths = [128, 64, 32, 16]\n",
        "model = TwoCats(           # 2 Cats\n",
        "    [                      # Is a sequence of\n",
        "        TransformLayer(    # Monotonic Transforms\n",
        "            PositiveLayer(\n",
        "                layer_widths,\n",
        "                EluPOne, EluPOne, EluPOne\n",
        "            ) # Defined by a positive NN\n",
        "        )\n",
        "    ],\n",
        "    FlexibleBi()           # Copulated with some bivariate CDF\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg99AIo7uKok"
      },
      "source": [
        "# Boston Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlRJSg8VuLZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754433be-24ab-4db9-c92d-f2dfa9e3c4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 953)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_loader = GOOG_FB()\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lagrangian(params, cop_state, nn_C, nn_dC):\n",
        "    Ex_M0 = cop_state.UV_batches[:, 0, :].ravel()\n",
        "    In_M0 = cop_state.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "    Ex_M1 = cop_state.UV_batches[:, 1, :].ravel()\n",
        "    In_M1 = cop_state.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "    Pr_M0_H = nn_C(params, In_M0).ravel()\n",
        "    Pr_M1_H = nn_C(params, In_M1).ravel()\n",
        "\n",
        "    Pr_M0_dH = nn_dC(params, In_M0)[:, 1, :].ravel()\n",
        "    Pr_M1_dH = nn_dC(params, In_M1)[:, 0, :].ravel()\n",
        "\n",
        "    lag_0 = (Pr_M0_H - Ex_M0) * (Pr_M0_dH - 1)\n",
        "    lag_1 = (Pr_M1_H - Ex_M1) * (Pr_M1_dH - 1)\n",
        "\n",
        "    return (lag_0 + lag_1).mean()"
      ],
      "metadata": {
        "id": "JUtS9DAHIriV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b4JqYLueX4"
      },
      "outputs": [],
      "source": [
        "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
        "    model, TrainingTensors, losses, rescale=True\n",
        ")\n",
        "\n",
        "def new_forward(params, cop_state, penalty):\n",
        "    f =  forward(params, cop_state)\n",
        "    l =  penalty * f[0]\n",
        "    l += lagrangian(params, cop_state, nn_C, nn_dC)\n",
        "    return l, f[1]\n",
        "\n",
        "new_grad = jax.grad(new_forward, has_aux=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTPcrb9uu3L8"
      },
      "outputs": [],
      "source": [
        "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
        "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
        "del subkey\n",
        "\n",
        "params = init_params\n",
        "optimizer = optax.adam(lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3UHmBVUu5O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c3b535-04bb-461c-98ca-f09f6a2f9392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1000 [00:48<13:32:30, 48.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. Loss [[ 0.16602299  0.05054328 -0.5936171 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 11/1000 [01:09<14:18,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. Loss [[ 0.1475725   0.02930159 -1.222151  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 21/1000 [01:11<03:54,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 20. Loss [[ 0.13354981  0.04496037 -1.6162444 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 31/1000 [01:13<03:45,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 30. Loss [[ 0.13018526  0.05750358 -1.7744995 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 41/1000 [01:16<03:30,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 40. Loss [[ 0.13190144  0.06529012 -1.8639513 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 52/1000 [01:18<03:27,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 50. Loss [[ 0.13281365  0.06192243 -1.875642  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 62/1000 [01:21<03:17,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 60. Loss [[ 0.13331412  0.06289008 -1.8970081 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 71/1000 [01:23<03:23,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 70. Loss [[ 0.13368466  0.06135058 -1.9006152 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 81/1000 [01:25<03:27,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. Loss [[ 0.13417226  0.0592202  -1.8963727 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 91/1000 [01:27<03:21,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 90. Loss [[ 0.13410373  0.06079324 -1.9094125 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 101/1000 [01:29<03:22,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 100. Loss [[ 0.1341772   0.06127141 -1.9149033 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 112/1000 [01:32<03:10,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 110. Loss [[ 0.13428754  0.06059353 -1.913614  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 122/1000 [01:34<03:08,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 120. Loss [[ 0.13430648  0.06038912 -1.9138826 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 131/1000 [01:36<03:18,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 130. Loss [[ 0.13507812  0.05437623 -1.8853837 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 142/1000 [01:38<03:03,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 140. Loss [[ 0.13536307  0.05527841 -1.8899531 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 151/1000 [01:41<03:08,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 150. Loss [[ 0.135308    0.05752761 -1.9006777 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 161/1000 [01:43<03:08,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 160. Loss [[ 0.1353301   0.05777817 -1.9030476 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 172/1000 [01:45<02:55,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 170. Loss [[ 0.13536066  0.05757481 -1.9033929 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 181/1000 [01:47<03:03,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 180. Loss [[ 0.13536148  0.05745586 -1.9037358 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 191/1000 [01:50<03:04,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 190. Loss [[ 0.13533452  0.05773225 -1.9052769 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 202/1000 [01:52<02:54,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 200. Loss [[ 0.13530841  0.05776135 -1.9057212 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 212/1000 [01:54<02:50,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 210. Loss [[ 0.1352387   0.05834522 -1.9082221 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 222/1000 [01:57<02:46,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 220. Loss [[ 0.13521153  0.05862523 -1.9093325 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 231/1000 [01:59<02:59,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 230. Loss [[ 0.13527174  0.05795883 -1.9065129 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 242/1000 [02:01<02:50,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 240. Loss [[ 0.13530286  0.05752032 -1.9047729 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 252/1000 [02:03<02:54,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 250. Loss [[ 0.13521881  0.05842589 -1.9084092 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 262/1000 [02:06<03:01,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 260. Loss [[ 0.13529767  0.0573692  -1.9041188 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 271/1000 [02:08<03:21,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 270. Loss [[ 0.13529482  0.0572744  -1.9035795 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 281/1000 [02:10<03:14,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 280. Loss [[ 0.13525866  0.05752208 -1.9044532 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 291/1000 [02:12<02:26,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 290. Loss [[ 0.13531315  0.05670191 -1.9009911 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 301/1000 [02:14<02:24,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 300. Loss [[ 0.13532375  0.05647508 -1.8998681 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 312/1000 [02:17<02:16,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 310. Loss [[ 0.1352339  0.0574265 -1.9036497]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 321/1000 [02:19<02:16,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 320. Loss [[ 0.13513725  0.05865952 -1.9078101 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 332/1000 [02:21<02:17,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 330. Loss [[ 0.13502598  0.06007715 -1.911639  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 342/1000 [02:23<02:15,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 340. Loss [[ 0.13506667  0.05946771 -1.9096932 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 352/1000 [02:26<02:10,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 350. Loss [[ 0.1349753   0.06094181 -1.9129093 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 361/1000 [02:28<02:09,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 360. Loss [[ 0.13486879  0.06306484 -1.9159136 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 371/1000 [02:30<02:12,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 370. Loss [[ 0.1348419   0.06367355 -1.9156026 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 381/1000 [02:32<02:12,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 380. Loss [[ 0.13490061  0.06285551 -1.9136461 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 391/1000 [02:35<02:05,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 390. Loss [[ 0.1348621   0.06364028 -1.9137342 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 401/1000 [02:37<02:05,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 400. Loss [[ 0.13486552  0.06319901 -1.9135534 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 411/1000 [02:39<02:02,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 410. Loss [[ 0.13482633  0.06352786 -1.9145486 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 421/1000 [02:41<02:02,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 420. Loss [[ 0.13480906  0.06344759 -1.9152693 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 431/1000 [02:44<02:01,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 430. Loss [[ 0.13483903  0.06293194 -1.9145999 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 441/1000 [02:46<01:58,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 440. Loss [[ 0.1349472   0.06107264 -1.9116939 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 452/1000 [02:48<01:51,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 450. Loss [[ 0.13505876  0.05934636 -1.9078162 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 462/1000 [02:51<01:48,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 460. Loss [[ 0.13512993  0.05851336 -1.9052624 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 472/1000 [02:53<01:47,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 470. Loss [[ 0.13505529  0.06000651 -1.9083256 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 482/1000 [02:55<01:46,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 480. Loss [[ 0.13499747  0.06116696 -1.9103094 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 491/1000 [02:57<01:48,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 490. Loss [[ 0.13498278  0.06162833 -1.9113481 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 501/1000 [03:00<01:46,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 500. Loss [[ 0.13512586  0.05908142 -1.9066057 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 512/1000 [03:02<01:38,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 510. Loss [[ 0.13510972  0.05927051 -1.9073864 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 522/1000 [03:04<01:39,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 520. Loss [[ 0.13509533  0.0594035  -1.9079292 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 532/1000 [03:06<01:37,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 530. Loss [[ 0.13501807  0.06040759 -1.9108638 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 541/1000 [03:09<01:39,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 540. Loss [[ 0.13501249  0.06024096 -1.9109054 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 551/1000 [03:11<01:37,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 550. Loss [[ 0.13512489  0.0584361  -1.905958  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 561/1000 [03:13<01:36,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 560. Loss [[ 0.13511235  0.05883843 -1.9070013 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 571/1000 [03:15<01:35,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 570. Loss [[ 0.13502027  0.06047059 -1.9110624 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 582/1000 [03:18<01:27,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 580. Loss [[ 0.13493821  0.06227038 -1.9143964 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 592/1000 [03:20<01:25,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 590. Loss [[ 0.13491559  0.06280706 -1.9151512 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 601/1000 [03:22<01:25,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 600. Loss [[ 0.13495456  0.06185782 -1.9139413 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 611/1000 [03:24<01:21,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 610. Loss [[ 0.135005    0.06085652 -1.9119797 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 622/1000 [03:27<01:18,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 620. Loss [[ 0.1348907   0.06259318 -1.914801  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 632/1000 [03:29<01:16,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 630. Loss [[ 0.13504496  0.06040166 -1.9105548 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 642/1000 [03:31<01:12,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 640. Loss [[ 0.13513677  0.05903161 -1.9064437 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 651/1000 [03:33<01:16,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 650. Loss [[ 0.13520889  0.05801179 -1.902559  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 661/1000 [03:36<01:11,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 660. Loss [[ 0.1352594   0.05738126 -1.9001015 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 671/1000 [03:38<01:12,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 670. Loss [[ 0.13528548  0.05706666 -1.8987086 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 682/1000 [03:40<01:04,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 680. Loss [[ 0.13543914  0.0553538  -1.8917664 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 691/1000 [03:42<01:04,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 690. Loss [[ 0.13558604  0.0540491  -1.885396  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 701/1000 [03:45<01:05,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 700. Loss [[ 0.13565017  0.05366384 -1.8830855 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 712/1000 [03:47<00:59,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 710. Loss [[ 0.13575156  0.05288328 -1.8792156 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 722/1000 [03:49<00:59,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 720. Loss [[ 0.13575034  0.05302439 -1.8798898 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 732/1000 [03:52<00:55,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 730. Loss [[ 0.13564637  0.05426271 -1.8856184 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 741/1000 [03:54<00:57,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 740. Loss [[ 0.13557276  0.05528975 -1.889389  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 751/1000 [03:56<00:55,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 750. Loss [[ 0.13552336  0.0561039  -1.8918202 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 761/1000 [03:58<00:52,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 760. Loss [[ 0.13554572  0.05592563 -1.8909833 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 771/1000 [04:01<00:50,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 770. Loss [[ 0.1355962   0.05569431 -1.889523  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 782/1000 [04:03<00:45,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 780. Loss [[ 0.13557854  0.05627997 -1.8906115 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 792/1000 [04:05<00:44,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 790. Loss [[ 0.13565429  0.0554052  -1.8873516 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 801/1000 [04:07<00:43,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 800. Loss [[ 0.13577282  0.05396937 -1.8816969 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 812/1000 [04:10<00:40,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 810. Loss [[ 0.13581385  0.05376314 -1.879876  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 821/1000 [04:12<00:38,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 820. Loss [[ 0.13580558  0.05418688 -1.8806769 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 832/1000 [04:14<00:35,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 830. Loss [[ 0.13587964  0.05331827 -1.8771958 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 842/1000 [04:16<00:34,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 840. Loss [[ 0.13593411  0.05282784 -1.8743758 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 852/1000 [04:19<00:31,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 850. Loss [[ 0.13593514  0.05276772 -1.8735332 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 861/1000 [04:21<00:34,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 860. Loss [[ 0.13610166  0.05089975 -1.8644319 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 872/1000 [04:23<00:28,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 870. Loss [[ 0.13607877  0.05111675 -1.8651601 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 881/1000 [04:25<00:30,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 880. Loss [[ 0.136077   0.0512057 -1.8653392]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 891/1000 [04:28<00:26,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 890. Loss [[ 0.1362341   0.04974074 -1.8569623 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 901/1000 [04:30<00:26,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 900. Loss [[ 0.13640168  0.04843568 -1.8483074 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 911/1000 [04:32<00:24,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 910. Loss [[ 0.13659808  0.04702686 -1.8376052 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 921/1000 [04:34<00:21,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 920. Loss [[ 0.13654321  0.04751989 -1.8419961 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 931/1000 [04:37<00:18,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 930. Loss [[ 0.13644601  0.04838903 -1.8484478 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 941/1000 [04:39<00:16,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 940. Loss [[ 0.13642797  0.04874713 -1.8507216 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 951/1000 [04:41<00:13,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 950. Loss [[ 0.13639346  0.04917442 -1.8530233 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 961/1000 [04:43<00:10,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 960. Loss [[ 0.13647375  0.04844945 -1.848294  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 972/1000 [04:46<00:07,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 970. Loss [[ 0.13658495  0.04754009 -1.8421634 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 982/1000 [04:48<00:04,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 980. Loss [[ 0.13663733  0.04713    -1.8390253 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 991/1000 [04:50<00:01,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 990. Loss [[ 0.1366384   0.04708282 -1.8383    ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [04:52<00:00,  3.42it/s]\n"
          ]
        }
      ],
      "source": [
        "def L_d(losses, params, state):\n",
        "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
        "    for i, (w, loss_func) in enumerate(losses):\n",
        "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
        "    return loss\n",
        "\n",
        "best = 1e6\n",
        "mu = 1\n",
        "alpha = 0.95\n",
        "for i in tqdm(range(n_iter)):\n",
        "    grads, cop_state = new_grad(params, cop_state, mu)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    mu = mu * alpha\n",
        "    loss = L_d(losses_eval, params, cop_state)\n",
        "    if not jnp.isnan(loss).any():\n",
        "        best_params = params\n",
        "        best_cop_state = cop_state\n",
        "        best = loss[0][-1]\n",
        "    else:\n",
        "        break\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print('Iter {}. Loss {}'.format(i, loss))\n",
        "\n",
        "# best_params = params\n",
        "# best_cop_state = cop_state\n",
        "# best = loss[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTTpwjSAAgxF",
        "outputId": "47793115-e163-4db9-8af0-cb6ae7b7bbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.291822747744796e-23"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ex_M0 = TrainingTensors.UV_batches[:, 0, :].ravel()\n",
        "In_M0 = TrainingTensors.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "Ex_M1 = TrainingTensors.UV_batches[:, 1, :].ravel()\n",
        "In_M1 = TrainingTensors.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "Pr_M0 = nn_C(params, In_M0).ravel()\n",
        "Pr_M1 = nn_C(params, In_M1).ravel()\n",
        "\n",
        "plt.hist((Ex_M0 - Pr_M0) / Ex_M0, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "KfHQloco9FlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "313f15ac-9c72-4031-d71f-3a721fe81a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.29905561, 0.39454354, 0.46379853, 0.52256033, 0.57712487,\n",
              "        0.63273872, 0.69359916, 0.76915005, 0.87198321, 1.        ]),\n",
              " array([-6.33775606e-04,  8.28732997e-02,  1.66380376e-01,  2.49887466e-01,\n",
              "         3.33394527e-01,  4.16901618e-01,  5.00408709e-01,  5.83915770e-01,\n",
              "         6.67422831e-01,  7.50929952e-01,  8.34437013e-01]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist((Ex_M1 - Pr_M1) / Ex_M1, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "ci44OZkz9_vq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "133ed488-59d4-4cd5-ed26-10778a91b31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.31059812, 0.46589717, 0.59706191, 0.71458552, 0.81636936,\n",
              "        0.89926548, 0.95487933, 0.98426023, 0.99580273, 1.        ]),\n",
              " array([-0.00188178,  0.05280528,  0.10749234,  0.1621794 ,  0.21686645,\n",
              "         0.27155352,  0.32624057,  0.38092762,  0.43561471,  0.49030176,\n",
              "         0.54498881]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX-VRCYivJC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde58150-3018-4b23-a618-6c5085eb7249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0052465894 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1d58ef50d380>:6: RuntimeWarning: invalid value encountered in log\n",
            "  yhat = -np.log(points_density)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.2002004"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLPnSwayvDYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36939370-095b-49f0-cf83-7effe2348594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.1434181"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjKd8d6N2FpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9155edc0-85d2-428d-84c7-3db79797fc4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.036216382,\n",
              " ConfidenceInterval(low=-1.2074383534403783, high=-1.0642009827864105))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "res = bootstrap(yhat, np.nanmean)\n",
        "res.standard_error, res.confidence_interval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M0 - Pr_M0) / Ex_M0).mean()"
      ],
      "metadata": {
        "id": "Bf5LV4s0L_sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c6236e-73e2-45fa-9811-19d59477aceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(35.097507, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M1 - Pr_M1) / Ex_M1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15kB3bZCAar1",
        "outputId": "3ba92369-bd78-4b5c-b866-8aaad6ae6d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(14.585156, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(jnp.abs(Ex_M0 - Pr_M0)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci5WxKPPwHWj",
        "outputId": "79240ccc-4a85-496f-af19-6e1a3312319f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.09251422, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(jnp.abs(Ex_M1 - Pr_M1)).mean()"
      ],
      "metadata": {
        "id": "-KzqKEBcAc6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2519fe10-46c8-4743-8d8a-847200edd7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.03850865, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hplqbTcswG2H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}