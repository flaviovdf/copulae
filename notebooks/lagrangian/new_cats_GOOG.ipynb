{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0eenMXFTSO"
      },
      "source": [
        "# Setup\n",
        "\n",
        "## Basic import and setup. For double blindness, the github repo is a colab secret. Change this to run your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LlGHCmorIVx",
        "outputId": "07b8cb5a-1afe-425b-b475-ceba5cbd8610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-33961236\n"
          ]
        }
      ],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGAAAAJhLRB4MS0Qe\n",
        "DAAAAAtzc2gtZWQyNTUxOQAAACD8jZaTrZ9TVKDdO4JCLvyef6S9uqHcgXVwg7eP78oAGA\n",
        "AAAEAs22L4hryptljXrWDjUBvKiw5vWgqQ35mA9XsN2mxjdPyNlpOtn1NUoN07gkIu/J5/\n",
        "pL26odyBdXCDt4/vygAYAAAAFGZsYXZpb3ZkZkBiYWJ5YmVuZGVyAQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open('/root/.ssh/id_ed25519', 'w') as f:\n",
        "    f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_ed25519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsQWN3Qutf1",
        "outputId": "d875ce03-13ab-4672-8a3a-c2bf7fafea0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+ssh://****@github.com/flaviovdf/copulae.git\n",
            "  Cloning ssh://****@github.com/flaviovdf/copulae.git to /tmp/pip-req-build-pwks3ob0\n",
            "  Running command git clone --filter=blob:none --quiet 'ssh://****@github.com/flaviovdf/copulae.git' /tmp/pip-req-build-pwks3ob0\n",
            "  Resolved ssh://****@github.com/flaviovdf/copulae.git to commit 006a8cdf39eadae9803918962d9b6f3443327ecf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from copulae==0.1)\n",
            "  Downloading coverage-7.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.7/231.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.8.3)\n",
            "Collecting flake8 (from copulae==0.1)\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (7.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from copulae==0.1) (0.14.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->copulae==0.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->copulae==0.1)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8->copulae==0.1)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->copulae==0.1) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->copulae==0.1) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->copulae==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.1.86)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->copulae==0.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->copulae==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->copulae==0.1) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->copulae==0.1) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->copulae==0.1) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->copulae==0.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->copulae==0.1) (2.16.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->copulae==0.1) (3.20.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->copulae==0.1) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->copulae==0.1) (3.18.1)\n",
            "Building wheels for collected packages: copulae\n",
            "  Building wheel for copulae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for copulae: filename=copulae-0.1-py3-none-any.whl size=38382 sha256=117f7c362a3a7f976eb438f5b836087a6433ec2285997f3a2761b6fe21610a8f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ucgteadp/wheels/c4/a8/e8/250a08d940aa8b10fd5748c65191f09ee8f9026550ad53edfd\n",
            "Successfully built copulae\n",
            "Installing collected packages: pyflakes, pycodestyle, mccabe, coverage, flake8, copulae\n",
            "Successfully installed copulae-0.1 coverage-7.5.1 flake8-7.0.0 mccabe-0.7.0 pycodestyle-2.11.1 pyflakes-3.2.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "! pip install {userdata.get('twocatsrepo')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3GILjJgBkOT"
      },
      "outputs": [],
      "source": [
        "from copulae.input import generate_copula_net_input\n",
        "\n",
        "from copulae.training import setup_training\n",
        "from copulae.training.loss import sq_error\n",
        "from copulae.training.loss import sq_error_partial\n",
        "from copulae.training.loss import copula_likelihood\n",
        "\n",
        "from copulae.training.cflax.mono_aux import EluPOne\n",
        "\n",
        "from copulae.training.cflax.two_cats import FlexibleBi\n",
        "from copulae.training.cflax.two_cats import NormalBi\n",
        "from copulae.training.cflax.two_cats import PositiveLayer\n",
        "from copulae.training.cflax.two_cats import TransformLayer\n",
        "from copulae.training.cflax.two_cats import TwoCats\n",
        "\n",
        "from copulae.typing import Tensor\n",
        "\n",
        "from scipy.stats import bootstrap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "\n",
        "import copy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy.stats as jss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import pandas as pd\n",
        "import scipy.stats as ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqYmiT-uvNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8o-Btitw9v"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use the 2d data from: https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59ZdlGCtyad"
      },
      "outputs": [],
      "source": [
        "def add_train_random_noise(data, num_adds):\n",
        "    new_data = np.random.rand(num_adds, data.shape[1])\n",
        "    return np.concatenate((data, new_data), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDHMLIEptyc3"
      },
      "outputs": [],
      "source": [
        "def rank_normalization(X):\n",
        "    X = copy.deepcopy(X)\n",
        "    for z in X:\n",
        "        ndata = z.shape[0]\n",
        "        gap = 1./(ndata+1)\n",
        "        nfeats = z.shape[1]\n",
        "        for i in range(nfeats):\n",
        "            z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmnDKhjxtyfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33729b0-e3c6-4eff-8621-a8d47b935697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gen-AC'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (466/466), done.\u001b[K\n",
            "remote: Compressing objects: 100% (339/339), done.\u001b[K\n",
            "remote: Total 466 (delta 159), reused 421 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (466/466), 10.28 MiB | 15.55 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yutingng/gen-AC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8rTp88Ityhd"
      },
      "outputs": [],
      "source": [
        "class Boston():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "        raw_df = pd.read_csv(data_url, sep = \"\\s+\", skiprows = 22, header = None)\n",
        "        X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "        y = raw_df.values[1::2, 2]\n",
        "\n",
        "        # split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 142857)\n",
        "        X_train = np.concatenate((X_train, y_train[:, None]), axis = 1)\n",
        "        X_test  = np.concatenate((X_test, y_test[:, None]), axis = 1)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # noise\n",
        "        X_train = add_train_random_noise(X_train, int(X_train.shape[0]*0.01))\n",
        "\n",
        "        # 2d\n",
        "        train_data = X_train[:, [0, 13]]\n",
        "        test_data = X_test[:, [0, 13]]\n",
        "\n",
        "        # flip\n",
        "        train_data[:, 0] = 1 - train_data[:, 0]\n",
        "        test_data[:, 0] = 1 - test_data[:, 0]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8liWvEt7wZBm"
      },
      "outputs": [],
      "source": [
        "class INTC_MSFT():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        intel_f = open('gen-AC/data/raw/INTC_MSFT_GE/INTEL.data', 'r')\n",
        "        intel = np.array(list(map(float, intel_f.readlines())))\n",
        "\n",
        "        ms_f = open('gen-AC/data/raw/INTC_MSFT_GE/MS.data', 'r')\n",
        "        ms = np.array(list(map(float, ms_f.readlines())))\n",
        "\n",
        "        ge_f = open('gen-AC/data/raw/INTC_MSFT_GE/GE.data', 'r')\n",
        "        ge = np.array(list(map(float, ge_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((intel[:, None], ms[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle = True, random_state = 142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2fnWDnywZEF"
      },
      "outputs": [],
      "source": [
        "class GOOG_FB():\n",
        "    def __init__(self):\n",
        "        # read\n",
        "        goog_f = open('gen-AC/data/raw/FB_GOOG/goog/close.vals', 'r')\n",
        "        goog = np.array(list(map(float, goog_f.readlines())))\n",
        "\n",
        "        fb_f = open('gen-AC/data/raw/FB_GOOG/fb/close.vals', 'r')\n",
        "        fb = np.array(list(map(float, fb_f.readlines())))\n",
        "\n",
        "        # split\n",
        "        X = np.concatenate((goog[:, None], fb[:, None]), axis = 1)\n",
        "        X_train, X_test, _, _ = train_test_split(X, X, shuffle=True, random_state=142857)\n",
        "\n",
        "        # norm\n",
        "        [X_train, X_test] = rank_normalization([X_train, X_test])\n",
        "\n",
        "        # 2d, noise\n",
        "        train_data = X_train[:, [0, 1]]\n",
        "        train_data = add_train_random_noise(train_data, int(train_data.shape[0]*0.01))\n",
        "        test_data = X_test[:, [0, 1]]\n",
        "\n",
        "        self.train_y = train_data[:, 1].reshape(-1, 1)\n",
        "        self.train_x = train_data[:, 0].reshape(-1, 1)\n",
        "        self.validation_y = test_data[:, 1].reshape(-1, 1)\n",
        "        self.validation_x = test_data[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA7CUNiQ_VF7"
      },
      "outputs": [],
      "source": [
        "def get_set(D_val, data_points):\n",
        "    points = D_val\n",
        "    points = jnp.expand_dims(points, axis=0)\n",
        "\n",
        "    # PDF and CDF for X\n",
        "    kde_x = jss.gaussian_kde(data_points[0], bw_method='silverman')\n",
        "    density_x = kde_x.evaluate(points[0, 0, :])\n",
        "    cumulative_x = jnp.array([kde_x.integrate_box_1d(-jnp.inf, p) for p in points[0, 0, :]])\n",
        "\n",
        "    # PDF and CDF for Y\n",
        "    kde_y = jss.gaussian_kde(D[1], bw_method='silverman')\n",
        "    density_y = kde_y.evaluate(points[0, 1, :])\n",
        "    cumulative_y = jnp.array([kde_y.integrate_box_1d(-jnp.inf, p) for p in points[0, 1, :]])\n",
        "\n",
        "    I_pdf = density_x.T * density_y.T\n",
        "    I_pdf = jnp.expand_dims(I_pdf, axis=0)\n",
        "    cdf_xy = jnp.array((cumulative_x, cumulative_y))\n",
        "    cdf_xy = jnp.expand_dims(cdf_xy, axis=0)\n",
        "\n",
        "    del density_x\n",
        "    del density_y\n",
        "    del cumulative_x\n",
        "    del cumulative_y\n",
        "\n",
        "    return points, I_pdf, cdf_xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoNLVJh9tyly"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30091985)\n",
        "key = jax.random.PRNGKey(30091985)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrU2-FfguEXl"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yCf4X_muQBI"
      },
      "outputs": [],
      "source": [
        "losses = [\n",
        "    (0.01, sq_error),\n",
        "    (0.5, sq_error_partial),\n",
        "    (0.1, copula_likelihood),\n",
        "]\n",
        "lr = 2e-2\n",
        "n_iter = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmYBAhoVuExA"
      },
      "outputs": [],
      "source": [
        "losses_eval = [\n",
        "    (1.0, sq_error),\n",
        "    (1.0, sq_error_partial),\n",
        "    (1.0, copula_likelihood),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxPVIuCsugBt"
      },
      "outputs": [],
      "source": [
        "layer_widths = [128, 64, 32, 16]\n",
        "model = TwoCats(           # 2 Cats\n",
        "    [                      # Is a sequence of\n",
        "        TransformLayer(    # Monotonic Transforms\n",
        "            PositiveLayer(\n",
        "                layer_widths,\n",
        "                EluPOne, EluPOne, EluPOne\n",
        "            ) # Defined by a positive NN\n",
        "        )\n",
        "    ],\n",
        "    FlexibleBi()           # Copulated with some bivariate CDF\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg99AIo7uKok"
      },
      "source": [
        "# Boston Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlRJSg8VuLZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b544ef32-56fe-46fd-a8d3-45158a6e4a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-ace2504509e9>:8: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  z[:, i] = ss.stats.rankdata(z[:, i], 'ordinal')*gap\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 953)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "data_loader = GOOG_FB()\n",
        "D = np.array([data_loader.train_x, data_loader.train_y])[:, :, 0]\n",
        "TrainingTensors = generate_copula_net_input(\n",
        "    D=D,\n",
        "    bootstrap=False\n",
        ")\n",
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lagrangian(params, cop_state, nn_C, nn_dC):\n",
        "    Ex_M0 = cop_state.UV_batches[:, 0, :].ravel()\n",
        "    In_M0 = cop_state.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "    Ex_M1 = cop_state.UV_batches[:, 1, :].ravel()\n",
        "    In_M1 = cop_state.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "    Pr_M0_H = nn_C(params, In_M0).ravel()\n",
        "    Pr_M1_H = nn_C(params, In_M1).ravel()\n",
        "\n",
        "    Pr_M0_dH = nn_dC(params, In_M0)[:, 1, :].ravel()\n",
        "    Pr_M1_dH = nn_dC(params, In_M1)[:, 0, :].ravel()\n",
        "\n",
        "    lag_0 = (Pr_M0_H - Ex_M0) * (Pr_M0_dH - 1)\n",
        "    lag_1 = (Pr_M1_H - Ex_M1) * (Pr_M1_dH - 1)\n",
        "\n",
        "    return (lag_0 + lag_1).mean()"
      ],
      "metadata": {
        "id": "JUtS9DAHIriV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76b4JqYLueX4"
      },
      "outputs": [],
      "source": [
        "nn_C, nn_dC, nn_c, cop_state, forward, grad = setup_training(\n",
        "    model, TrainingTensors, losses, rescale=True\n",
        ")\n",
        "\n",
        "def new_forward(params, cop_state, penalty):\n",
        "    f =  forward(params, cop_state)\n",
        "    l =  penalty * f[0]\n",
        "    l += lagrangian(params, cop_state, nn_C, nn_dC)\n",
        "    return l, f[1]\n",
        "\n",
        "new_grad = jax.grad(new_forward, has_aux=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTPcrb9uu3L8"
      },
      "outputs": [],
      "source": [
        "_, subkey = jax.random.split(key) # keep the old key as it will seed all other models\n",
        "init_params = model.init(subkey, TrainingTensors.UV_batches[0])\n",
        "del subkey\n",
        "\n",
        "params = init_params\n",
        "optimizer = optax.adam(lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3UHmBVUu5O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feea660-fb05-47de-a829-0f2c7e8f76f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/500 [00:46<6:25:02, 46.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0. Loss [[ 0.16602299  0.05054328 -0.5936171 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 12/500 [01:05<05:13,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. Loss [[ 0.1579855   0.02871744 -0.7761326 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 22/500 [01:08<01:46,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 20. Loss [[ 0.1537296   0.0189622  -0.98724777]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 31/500 [01:09<01:45,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 30. Loss [[ 0.15135534  0.01700162 -1.0715541 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 42/500 [01:12<01:38,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 40. Loss [[ 0.14881091  0.0218169  -1.1910875 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 52/500 [01:14<01:36,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 50. Loss [[ 0.14810406  0.02901375 -1.2604221 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 62/500 [01:16<01:35,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 60. Loss [[ 0.14789364  0.0331076  -1.2877551 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 72/500 [01:18<01:36,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 70. Loss [[ 0.14777704  0.03481831 -1.2979383 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 82/500 [01:20<01:34,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. Loss [[ 0.1477109   0.03547446 -1.3020514 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 92/500 [01:23<01:33,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 90. Loss [[ 0.1476767   0.03572685 -1.303791  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 102/500 [01:25<01:30,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 100. Loss [[ 0.14765066  0.0358133  -1.3046039 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 112/500 [01:27<01:29,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 110. Loss [[ 0.14762747  0.03578348 -1.3049306 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 122/500 [01:29<01:25,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 120. Loss [[ 0.1476198   0.03584817 -1.3054076 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 132/500 [01:31<01:23,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 130. Loss [[ 0.14761358  0.03584907 -1.3054737 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 142/500 [01:33<01:23,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 140. Loss [[ 0.14761525  0.03591397 -1.305693  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 152/500 [01:36<01:22,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 150. Loss [[ 0.14761825  0.03600013 -1.3059729 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 162/500 [01:38<01:19,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 160. Loss [[ 0.14761667  0.03606211 -1.3061879 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 172/500 [01:40<01:17,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 170. Loss [[ 0.1476158   0.03609948 -1.3062471 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 181/500 [01:42<01:02,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 180. Loss [[ 0.14762086  0.03619199 -1.306332  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 191/500 [01:44<01:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 190. Loss [[ 0.14763002  0.03634604 -1.3065943 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 202/500 [01:46<00:57,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 200. Loss [[ 0.14763497  0.03652281 -1.3069518 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 212/500 [01:48<00:55,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 210. Loss [[ 0.14764921  0.03677056 -1.3067728 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 222/500 [01:50<00:54,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 220. Loss [[ 0.14767395  0.03703148 -1.2940499 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 232/500 [01:52<00:51,  5.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 230. Loss [[ 0.14769104  0.03727267 -1.2950263 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 242/500 [01:55<00:49,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 240. Loss [[ 0.14766817  0.03728614 -1.2952316 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 252/500 [01:57<00:49,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 250. Loss [[ 0.14765058  0.03733264 -1.2956398 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 262/500 [01:59<00:46,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 260. Loss [[ 0.14763828  0.03738073 -1.2959222 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 272/500 [02:01<00:44,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 270. Loss [[ 0.14761305  0.037362   -1.2958943 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 282/500 [02:03<00:43,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 280. Loss [[ 0.14758421  0.03735381 -1.296052  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 292/500 [02:05<00:40,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 290. Loss [[ 0.1475636   0.03743587 -1.2965462 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 302/500 [02:07<00:39,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 300. Loss [[ 0.14754802  0.03746204 -1.2966475 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 311/500 [02:09<00:37,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 310. Loss [[ 0.14752755  0.03741284 -1.2964606 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 322/500 [02:12<00:35,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 320. Loss [[ 0.14751333  0.03746392 -1.2967466 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 332/500 [02:14<00:32,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 330. Loss [[ 0.14751244  0.03762854 -1.2975186 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 342/500 [02:16<00:30,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 340. Loss [[ 0.14749545  0.03781356 -1.298613  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 352/500 [02:18<00:29,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 350. Loss [[ 0.1474699   0.03786502 -1.2991083 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 362/500 [02:20<00:27,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 360. Loss [[ 0.14743458  0.03776022 -1.309756  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 372/500 [02:22<00:24,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 370. Loss [[ 0.14740752  0.03770172 -1.3122181 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 382/500 [02:25<00:22,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 380. Loss [[ 0.14736032  0.0375885  -1.3133351 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 392/500 [02:27<00:21,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 390. Loss [[ 0.14732458  0.03748784 -1.3135954 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 402/500 [02:29<00:19,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 400. Loss [[ 0.14730255  0.03753981 -1.3140476 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 411/500 [02:31<00:18,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 410. Loss [[ 0.1472818   0.03766321 -1.3148541 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 422/500 [02:33<00:15,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 420. Loss [[ 0.14727966  0.03786149 -1.3154249 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 432/500 [02:35<00:13,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 430. Loss [[ 0.14727756  0.03803609 -1.3156955 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 442/500 [02:37<00:11,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 440. Loss [[ 0.14726768  0.03811954 -1.3162591 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 452/500 [02:39<00:09,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 450. Loss [[ 0.147279    0.03823868 -1.3162091 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 462/500 [02:42<00:07,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 460. Loss [[ 0.14727819  0.03836816 -1.3168607 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 472/500 [02:44<00:05,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 470. Loss [[ 0.14726292  0.03840115 -1.3177032 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▋| 482/500 [02:46<00:03,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 480. Loss [[ 0.14721     0.03820072 -1.3178874 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 492/500 [02:48<00:01,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 490. Loss [[ 0.14715184  0.03800121 -1.3178905 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [02:50<00:00,  2.94it/s]\n"
          ]
        }
      ],
      "source": [
        "def L_d(losses, params, state):\n",
        "    loss = jnp.zeros((1,len(losses)), dtype=jnp.float32)\n",
        "    for i, (w, loss_func) in enumerate(losses):\n",
        "        loss = loss.at[0, i].set(w * loss_func(params, state))\n",
        "    return loss\n",
        "\n",
        "best = 1e6\n",
        "mu = 1\n",
        "alpha = 0.85\n",
        "for i in tqdm(range(n_iter)):\n",
        "    grads, cop_state = new_grad(params, cop_state, mu)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    mu = mu * alpha\n",
        "    loss = L_d(losses_eval, params, cop_state)\n",
        "    if not jnp.isnan(loss).any():\n",
        "        best_params = params\n",
        "        best_cop_state = cop_state\n",
        "        best = loss[0][-1]\n",
        "    else:\n",
        "        break\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print('Iter {}. Loss {}'.format(i, loss))\n",
        "\n",
        "# best_params = params\n",
        "# best_cop_state = cop_state\n",
        "# best = loss[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTTpwjSAAgxF",
        "outputId": "a38c1b39-eea3-4d14-d3ca-df71d978c1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.122274603521788e-36"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ex_M0 = TrainingTensors.UV_batches[:, 0, :].ravel()\n",
        "In_M0 = TrainingTensors.UV_batches.at[:, 1, :].set(1)\n",
        "\n",
        "Ex_M1 = TrainingTensors.UV_batches[:, 1, :].ravel()\n",
        "In_M1 = TrainingTensors.UV_batches.at[:, 0, :].set(1)\n",
        "\n",
        "Pr_M0 = nn_C(params, In_M0).ravel()\n",
        "Pr_M1 = nn_C(params, In_M1).ravel()\n",
        "\n",
        "plt.hist((Ex_M0 - Pr_M0) / Ex_M0, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "KfHQloco9FlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "76df67b9-5456-47f9-9399-1faadd90cc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00839454, 0.03147954, 0.0703043 , 0.12381952, 0.19517314,\n",
              "        0.28856243, 0.41133263, 0.56663169, 0.75865687, 1.        ]),\n",
              " array([-3.78023714e-01, -3.40221226e-01, -3.02418768e-01, -2.64616281e-01,\n",
              "        -2.26813793e-01, -1.89011320e-01, -1.51208848e-01, -1.13406360e-01,\n",
              "        -7.56038874e-02, -3.78014073e-02,  1.07288361e-06]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist((Ex_M1 - Pr_M1) / Ex_M1, cumulative=True, density=True, edgecolor='w')"
      ],
      "metadata": {
        "id": "ci44OZkz9_vq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "cc062fd0-9cd1-479c-a475-3c28f964138f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.12172088, 0.20251836, 0.28961175, 0.38195173, 0.4795383 ,\n",
              "        0.58237146, 0.68625393, 0.79328437, 0.89926548, 1.        ]),\n",
              " array([-2.23150045e-01, -2.00834930e-01, -1.78519815e-01, -1.56204715e-01,\n",
              "        -1.33889601e-01, -1.11574486e-01, -8.92593712e-02, -6.69442639e-02,\n",
              "        -4.46291491e-02, -2.23140381e-02,  1.07288361e-06]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX-VRCYivJC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f23630-9d70-4113-e40b-a129ed6ec9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0031479537 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-1d58ef50d380>:6: RuntimeWarning: invalid value encountered in log\n",
            "  yhat = -np.log(points_density)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.8250826"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "density_graph_points, I_pdf, cdf_xy = get_set(D, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLPnSwayvDYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc29717-5d92-4264-dde6-433075df8623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.7748252"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "D_val = np.array([data_loader.validation_x, data_loader.validation_y])[:, :, 0]\n",
        "density_graph_points, I_pdf, cdf_xy = get_set(D_val, best_cop_state.X_batches[0])\n",
        "\n",
        "copula_density = nn_c(best_params, cdf_xy)\n",
        "points_density = copula_density * I_pdf\n",
        "print((points_density < 0).mean(), (points_density < 0).sum())\n",
        "yhat = -np.log(points_density)\n",
        "np.nanmean(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjKd8d6N2FpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9891c3a7-c9b0-46ba-f5ff-e75e96e79697"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.031068936,\n",
              " ConfidenceInterval(low=-0.8328221002614201, high=-0.7104104825811868))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "res = bootstrap(yhat, np.nanmean)\n",
        "res.standard_error, res.confidence_interval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M0 - Pr_M0) / Ex_M0).mean()"
      ],
      "metadata": {
        "id": "Bf5LV4s0L_sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9c2eee-8223-47c3-e4e3-4bd6a105c165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(11.078949, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (jnp.abs(Ex_M1 - Pr_M1) / Ex_M1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15kB3bZCAar1",
        "outputId": "4f0ae9bf-6a4e-445d-83d8-c4cb80748727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(11.04645, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KzqKEBcAc6y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}